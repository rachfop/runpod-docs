openapi: 3.1.0
info:
  title: Endpoints
  version: '1.0'
  description: |-
    Interact with the serverless Quick Start APIs.

    ## Prerequisites

    You will need a RunPod API key which can be generated under your user settings.
    This API key will identify you for billing purposes, so guard it well!

    You must retrieve your results via the status endpoint within 30 minutes.
    We do not keep your inputs or outputs longer than that to protect your privacy!


    ## Overview

    Our initial API implementation works asynchronously. This means you fire an API request to our endpoint with your input parameters and immediately get a response with a unique job ID. What do I do with this useless response, you say? You can then query the status endpoint and pass it your job ID. The status endpoint will give you the job results when completed.

    Let's take the Stable Diffusion v1 inference endpoint, for example.

    ### Start your job

    You would first make a request like the following (remember to replace the "xxxxxx"s with your real API key:

    ```curl
    curl -X POST https://api.runpod.ai/v2/stable-diffusion-v1/run \
        -H 'Content-Type: application/json'                             \
        -H 'Authorization: Bearer xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'    \
        -d '{"input": {"prompt": "a cute magical flying dog, fantasy art drawn by disney concept artists"}}'
    ```

    You would get an immediate response that looks like this:

    ```json
    {
      "id": "c80ffee4-f315-4e25-a146-0f3d98cf024b",
      "status": "IN_QUEUE"
    }
    ```

    In this example, your job ID would be "c80ffee4-f315-4e25-a146-0f3d98cf024b". You get a new one for each job, and it is a unique identifier for your job.

    ### Check the status of your job

    You haven't gotten any output, so you must make an additional call to the status endpoint after some time. Your status endpoint uses the job ID to route to the correct job status. In this case, the status endpoint is

    ```
    https://api.runpod.ai/v1/stable-diffusion-v1/status/c80ffee4-f315-4e25-a146-0f3d98cf024b
    ```

    Note how the last part of the URL is your job ID. You could request that endpoint like so. Remember to use your API key for this request too!

    ```curl
    curl https://api.runpod.ai/v2/stable-diffusion-v1/status/c80ffee4-f315-4e25-a146-0f3d98cf024b \
        -H 'Content-Type: application/json' \
        -H 'Authorization: Bearer xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'
    ```

    If your job hasn't been completed, you may get something that looks like this back:

    ```json
    {
      "delayTime": 2624,
      "id": "c80ffee4-f315-4e25-a146-0f3d98cf024b",
      "input": {
        "prompt": "a cute magical flying dog, fantasy art drawn by disney concept artists"
      },
      "status": "IN_PROGRESS"
    }
    ```

    This means to wait a bit longer before you query the status endpoint again.

    ## Get completed job status

    Eventually, you will get the final results of your job. They would look something like this:

    ```json
    {
      "delayTime": 123456, // (milliseconds) time in queue
      "executionTime": 1234, // (milliseconds) time it took to complete the job
      "gpu": "24", // gpu type used to run the job
      "id": "c80ffee4-f315-4e25-a146-0f3d98cf024b",
      "input": {
        "prompt": "a cute magical flying dog, fantasy art drawn by disney concept artists"
      },
      "output": [
        {
          "image": "https://job.results1",
          "seed": 1
        },
        {
          "image": "https://job.results2",
          "seed": 2
        }
      ],
      "status": "COMPLETED"
    }
    ```

    _**Note: You must retrieve your results via the status endpoint within 1 hour. We do not keep your inputs or outputs longer than that to protect your privacy!**_

    ### Get your stuff

    Note how you don't get the images directly in the output. The output contains the URLs to the cloud storage that will let you download each image.

    You've successfully generated your first images with our Stable Diffusion API!

    If you want descriptions for all parameters and code examples past curl, read on!

    ### Rate Limit

    `/run` - 1000 requests every 10s

    `/runsync` - 2000 requests every 10s

    ## Retrieve Result and Status

    When a request is made using the `/run` endpoint, or if a job takes longer than 30 seconds to complete when using the `/runsync` endpoint, a job ID will be returned. This job ID is essential for tracking the progress of a job and obtaining its results upon completion. To do so, use the `/status/{job_id}` endpoint described below.

    ### Check Job Status and Retrieve Results

    To check the status of a job or retrieve its results once completed, make a request to the `/status/{job_id}` endpoint, replacing `{job_id}` with the specific job ID received earlier.

    1. **Checking job status:** If the job is still in progress, the endpoint will return the current status of the job (e.g., "IN_QUEUE", "IN_PROGRESS", "FAILED", "COMPLETED", ).
    2. **Retrieving job results:** If the job has been completed successfully, the endpoint will return the results of the job.

    Please note that you should periodically poll the `/status/{job_id}` endpoint to monitor the progress of your job and retrieve the results once it has finished.


    Job results are kept for up to 30 minutes after a job is completed.

servers:
  - url: https://api.runpod.ai/v2/
components:
  securitySchemes:
    sec0:
      type: apiKey
      in: header
      name: authorization
      x-default: ''
security:
  - sec0: []
paths:
  /controlnet-canny/{run_type}:
    post:
      summary: Canny
      description: This page will help you get started with ControlNet - Canny.
      operationId: controlnet-canny
      parameters:
        - name: run_type
          in: path
          description: |
            Run type, run returns a job ID and runsync returns the results in
            the same call if completed within 30 seconds.
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    image_url:
                      type: string
                      description: |
                        The URL for a publicly accessible image to be used as
                        the input.
                    image_base_64:
                      type: string
                      description: An input image in the format of base64.
                    prompt:
                      type: string
                      description: |
                        The prompt to be used to generate an image from, using
                        the source image as a guide.
                    a_prompt:
                      type: string
                      description: Additional text to be appended to prompt.
                      default: best quality, extremely detailed
                    n_prompt:
                      type: string
                      description: |
                        Negative prompt, things that you want to avoid in the
                        output image.
                      default: |
                        longbody, lowres, bad anatomy, bad hands, missing
                        fingers, extra digit, fewer digits, cropped, worst
                        quality, low quality
                    num_samples:
                      type: integer
                      description: |
                        Number of samples (higher values may OOM). Options:
                        ['1', '4']
                      default: 1
                      format: int32
                    image_resolution:
                      type: integer
                      description: |
                        Image resolution to be generated. Options: ['256',
                        '512', '768']
                      default: 512
                      format: int32
                    ddim_steps:
                      type: integer
                      description: Steps
                      default: 20
                      format: int32
                    scale:
                      type: number
                      description: 'Scale for classifier-free guidance. Options: 0.1 -> 30.0'
                      default: 9
                      format: float
                    seed:
                      type: integer
                      description: Seed for reproducibility.
                      default: null
                      format: int32
                    eta:
                      type: number
                      description: |
                        Controls the amount of noise that is added to the input
                        data during the denoising diffusion process. Higher
                        value -> more noise
                      default: 0
                      format: float
                    low_threshold:
                      type: integer
                      default: 100
                      format: int32
                    high_threshold:
                      type: integer
                      default: 200
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: The input parameters that can be used by ControlNet Canny.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |
                    {

                    "delayTime": 199231,

                    "executionTime": 10337,

                    "id": "73a50b0f-844c-4028-a2d2-946c8f0cf584",

                    "input": {

                    "image_url":
                    "https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg",

                    "prompt": "A frog performing yoga."

                    },

                    "output":
                    "https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2",

                    "status": "COMPLETED"

                    }
              schema:
                type: object
                properties:
                  delayTime:
                    type: integer
                    example: 199231
                    default: 0
                  executionTime:
                    type: integer
                    example: 10337
                    default: 0
                  id:
                    type: string
                    example: 73a50b0f-844c-4028-a2d2-946c8f0cf584
                  input:
                    type: object
                    properties:
                      image_url:
                        type: string
                        example: |
                          https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg
                      prompt:
                        type: string
                        example: A frog performing yoga.
                  output:
                    type: string
                    example: |
                      https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2
                  status:
                    type: string
                    example: COMPLETED
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /{endpoint_id}/status/{job_id}:
    post:
      summary: Retrieve Results & Status
      description: ''
      operationId: status
      parameters:
        - name: endpoint_id
          in: path
          description: The model name or endpoint id.
          schema:
            type: string
          required: true
        - name: job_id
          in: path
          description: The job id returned after your /run or /runsync request.
          schema:
            type: string
          required: true
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /stable-diffusion-v1/{run_type}:
    post:
      summary: Stable Diffusion v1
      description: A text-to-image model from StabilityAI
      operationId: stable-diffusion-v1
      parameters:
        - name: run_type
          in: path
          description: |
            Run type, run returns a job ID and runsync returns the results in
            the same call if completed within 30 seconds.
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      description: Your input prompt.
                      default: building 8 stories
                    negative_prompt:
                      type: string
                      description: Specify things to not see in the output.
                    width:
                      type: integer
                      description: |
                        Width of output image. Options: 128, 256, 384, 448, 512,
                        576, 640, 704, 768
                      default: 512
                      format: int32
                    height:
                      type: integer
                      description: |
                        Height of output image. Options: 128, 256, 384, 448,
                        512, 576, 640, 704, 768
                      default: 512
                      format: int32
                    init_image:
                      type: string
                      description: |
                        URL for an initial image to generate variations of. Will
                        be resized to the specific width and height.
                    mask:
                      type: string
                      description: |
                        URL of a black and white image to use as a mask for
                        inpainting over init_image. Black pixels are inpainted
                        and white pixels are preserved.
                    guidance_scale:
                      type: number
                      description: Scale for classifier-free guidance. Rage 1 - 20
                      default: 7.5
                      format: float
                    num_inference_steps:
                      type: integer
                      description: The number of denoising steps. Range 1 - 500
                      default: 50
                      format: int32
                    num_outputs:
                      type: integer
                      description: The number of images to output. Range 1 - 10
                      default: 1
                      format: int32
                    prompt_strength:
                      type: number
                      description: |
                        How much importance is given to the prompt. Range: 0.0 -
                        1.0
                      default: 1
                      format: float
                    scheduler:
                      type: string
                      description: |
                        Choose a scheduler. Options: GGIM, DDPM, DPM-M, DPM-S,
                        EULER-A, EULER-D, HEUN, IPNDM, KDPM2-A, KDPM2-D, PNDM,
                        KLMS
                      default: KLMS
                    seed:
                      type: integer
                      description: Random seed.
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: Input object contains prompt, and more.
                webhook:
                  type: string
                  description: |
                    URL endpoint to receive a webhook call on job complete,
                    fail, or timeout.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |-
                    {
                    "id": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
                    "status": "IN_QUEUE"
                    }
              schema:
                type: object
                properties:
                  id:
                    type: string
                    example: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
                  status:
                    type: string
                    example: IN_QUEUE
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '401':
          description: '401'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
        '429':
          description: '429'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
      deprecated: false
  /stable-diffusion-v2/{run_type}:
    post:
      summary: Stable Diffusion v2
      description: A text-to-image model from StabilityAI
      operationId: stable-diffusion-v2
      parameters:
        - name: run_type
          in: path
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      description: Your input prompt.
                      default: building 8 stories
                    negative_prompt:
                      type: string
                      description: Specify things to not see in the output.
                    height:
                      type: integer
                      description: |
                        Height of output image. Options: 128, 256, 384, 448,
                        512, 576, 640, 704, 768
                      default: 512
                      format: int32
                    width:
                      type: integer
                      description: |
                        Width of output image. Options: 128, 256, 384, 448, 512,
                        576, 640, 704, 768
                      default: 512
                      format: int32
                    prompt_strength:
                      type: number
                      description: How much importance is given to the prompt.
                      format: float
                    num_outputs:
                      type: integer
                      description: The number of images to output. Range 1 - 10
                      default: 1
                      format: int32
                    num_inference_steps:
                      type: integer
                      description: 'The number of denoising steps. Range: 1- 500'
                      default: 50
                      format: int32
                    guidance_scale:
                      type: number
                      description: Scale for classifier-free guidance.
                      default: 7.5
                      format: float
                    scheduler:
                      type: string
                      description: |
                        Choose a scheduler. Options: DDIM, K_EULER,
                        DPMSolverMultistep, K_EULER_ANCESTRAL, PNDM, KLMS
                      default: KLMS
                    seed:
                      type: integer
                      description: Random seed.
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: Input Object contains prompt, and more.
                webhook:
                  type: string
                  description: |
                    URL endpoint to receive a webhook call on job complete,
                    fail, or timeout.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |-
                    {
                    "id": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
                    "status": "IN_QUEUE"
                    }
              schema:
                type: object
                properties:
                  id:
                    type: string
                    example: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
                  status:
                    type: string
                    example: IN_QUEUE
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '401':
          description: '401'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
        '429':
          description: '429'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
      deprecated: false
  /sd-anything-v3/{run_type}:
    post:
      summary: Anything v3 (SD-v1.5)
      description: ''
      operationId: anything-v3
      parameters:
        - name: run_type
          in: path
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      description: Your input prompt.
                      default: building 8 stories
                    negative_prompt:
                      type: string
                      description: Specify things to not see in the output.
                    width:
                      type: integer
                      description: |
                        Width of output image. Options: 128, 256, 384, 448, 512,
                        576, 640, 704, 768
                      default: 512
                      format: int32
                    height:
                      type: integer
                      description: |
                        Height of output image. Options: 128, 256, 384, 448,
                        512, 576, 640, 704, 768
                      default: 512
                      format: int32
                    init_image:
                      type: string
                      description: |
                        URL for an initial image to generate variations of. Will
                        be resized to the specific width and height.
                    mask:
                      type: string
                      description: |
                        URL of a black and white image to use as a mask for
                        inpainting over init_image. Black pixels are inpainted
                        and white pixels are preserved.
                    guidance_scale:
                      type: number
                      description: 'Scale for classifier-free guidance. Range: 1-20'
                      default: 7.5
                      format: float
                    num_inference_steps:
                      type: integer
                      description: The number of denoising steps. Range 1-500
                      default: 50
                      format: int32
                    num_outputs:
                      type: integer
                      description: The number of images to output.
                      default: 1
                      format: int32
                    prompt_strength:
                      type: number
                      description: |
                        How much importance is given to the prompt. Range:
                        0.0-1.0
                      default: 0.8
                      format: float
                    scheduler:
                      type: string
                      description: 'Choose a scheduler. Options: DDIM, K-LMS, PNDM'
                      default: K-LMS
                    seed:
                      type: integer
                      description: Random seed.
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: Input Object contains prompt, and more.
                webhook:
                  type: string
                  description: |
                    URL endpoint to receive a webhook call on job complete,
                    fail, or timeout.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |-
                    {
                    "id": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
                    "status": "IN_QUEUE"
                    }
              schema:
                type: object
                properties:
                  id:
                    type: string
                    example: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
                  status:
                    type: string
                    example: IN_QUEUE
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '401':
          description: '401'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
        '429':
          description: '429'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
      deprecated: false
  /sd-anything-v4/{run_type}:
    post:
      summary: Anything v4 (SD-v1.5)
      description: ''
      operationId: anything-v4
      parameters:
        - name: Authorization
          in: header
          description: RunPod API Token
          required: true
          schema:
            type: string
        - name: run_type
          in: path
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      description: Your input prompt.
                      default: building 8 stories
                    negative_prompt:
                      type: string
                      description: Specify things to not see in the output.
                    width:
                      type: integer
                      description: |
                        Width of output image. Options: 128, 256, 384, 448, 512,
                        576, 640, 704, 768
                      default: 512
                      format: int32
                    height:
                      type: integer
                      description: |
                        Height of output image. Options: 128, 256, 384, 448,
                        512, 576, 640, 704, 768
                      default: 512
                      format: int32
                    init_image:
                      type: string
                      description: |
                        URL for an initial image to generate variations of. Will
                        be resized to the specific width and height.
                    mask:
                      type: string
                      description: |
                        URL of a black and white image to use as a mask for
                        inpainting over init_image. Black pixels are inpainted
                        and white pixels are preserved.
                    guidance_scale:
                      type: number
                      description: 'Scale for classifier-free guidance. Range: 1-20'
                      default: 7.5
                      format: float
                    num_inference_steps:
                      type: integer
                      description: The number of denoising steps. Range 1-500
                      default: 50
                      format: int32
                    num_outputs:
                      type: integer
                      description: The number of images to output.
                      default: 1
                      format: int32
                    prompt_strength:
                      type: number
                      description: |
                        How much importance is given to the prompt. Range:
                        0.0-1.0
                      default: 0.8
                      format: float
                    scheduler:
                      type: string
                      description: 'Choose a scheduler. Options: DDIM, K-LMS, PNDM'
                      default: K-LMS
                    seed:
                      type: integer
                      description: Random seed.
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: Input Object contains prompt, and more.
                webhook:
                  type: string
                  description: |
                    URL endpoint to receive a webhook call on job complete,
                    fail, or timeout.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |-
                    {
                    "id": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
                    "status": "IN_QUEUE"
                    }
              schema:
                type: object
                properties:
                  id:
                    type: string
                    example: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
                  status:
                    type: string
                    example: IN_QUEUE
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '401':
          description: '401'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
        '429':
          description: '429'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
      deprecated: false
  /sd-openjourney/{run_type}:
    post:
      summary: Openjourney (SD-v1.5)
      description: ''
      operationId: openjourney-sd-v15
      parameters:
        - name: Authorization
          in: header
          description: RunPod API Token
          required: true
          schema:
            type: string
        - name: run_type
          in: path
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      description: Your input prompt.
                      default: building 8 stories
                    negative_prompt:
                      type: string
                      description: Specify things to not see in the output.
                    width:
                      type: integer
                      description: |
                        Width of output image. Options: 128, 256, 384, 448, 512,
                        576, 640, 704, 768
                      default: 512
                      format: int32
                    height:
                      type: integer
                      description: |
                        Height of output image. Options: 128, 256, 384, 448,
                        512, 576, 640, 704, 768
                      default: 512
                      format: int32
                    init_image:
                      type: string
                      description: |
                        URL for an initial image to generate variations of. Will
                        be resized to the specific width and height.
                    mask:
                      type: string
                      description: |
                        URL of a black and white image to use as a mask for
                        inpainting over init_image. Black pixels are inpainted
                        and white pixels are preserved.
                    guidance_scale:
                      type: number
                      description: 'Scale for classifier-free guidance. Range: 1-20'
                      default: 7.5
                      format: float
                    num_inference_steps:
                      type: integer
                      description: The number of denoising steps. Range 1-500
                      default: 50
                      format: int32
                    num_outputs:
                      type: integer
                      description: The number of images to output.
                      default: 1
                      format: int32
                    prompt_strength:
                      type: number
                      description: |
                        How much importance is given to the prompt. Range:
                        0.0-1.0
                      default: 0.8
                      format: float
                    scheduler:
                      type: string
                      description: 'Choose a scheduler. Options: DDIM, K-LMS, PNDM'
                      default: K-LMS
                    seed:
                      type: integer
                      description: Random seed.
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: Input Object contains prompt, and more.
                webhook:
                  type: string
                  description: |
                    URL endpoint to receive a webhook call on job complete,
                    fail, or timeout.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |-
                    {
                    "id": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
                    "status": "IN_QUEUE"
                    }
              schema:
                type: object
                properties:
                  id:
                    type: string
                    example: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
                  status:
                    type: string
                    example: IN_QUEUE
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '401':
          description: '401'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
        '429':
          description: '429'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
      deprecated: false
  /dream-booth-v1/run:
    post:
      summary: DreamBooth (SD-v1.5)
      description: |
        DreamBooth is a deep learning generation model that fine-tunes existing
        text-to-image models such as Stable Diffusion.
      operationId: dreambooth-sd-v15
      parameters:
        - name: Authorization
          in: header
          description: RunPod API Token
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    train:
                      properties:
                        data_url:
                          type: string
                          description: |
                            A publicly accessible URL to your zip file
                            containing your data set images.
                        concept_name:
                          type: string
                          description: |
                            A unique name to train your concept with, this will
                            over-ride your file names using the following
                            scheme:  "concept (#).jpg"
                        offset_noise:
                          type: boolean
                          description: Enables offset noise for style training.
                          default: false
                        hf_model:
                          type: string
                          description: |
                            If the huggingface repo is private, your user access
                            token.
                        hf_token:
                          type: string
                          description: |
                            If the huggingface repo is private, your user access
                            token is required.
                        ckpt_link:
                          type: string
                          description: Publicly accessible link to a ckpt file.
                        text_steps:
                          type: integer
                          description: The number of steps used to train the text encoder.
                          default: 350
                          format: int32
                        text_seed:
                          type: integer
                          description: The seed used to train the text encoder.
                          default: 555
                          format: int32
                        text_batch_size:
                          type: integer
                          description: The seed used to train the text encoder.
                          default: 1
                          format: int32
                        text_resolution:
                          type: integer
                          description: The training resolution used for the text training.
                          default: 512
                          format: int32
                        text_learning_rate:
                          type: number
                          description: The learning rate for the  text encoder.
                          default: 0.000001
                          format: float
                        text_lr_scheduler:
                          type: string
                          description: |
                            The scheduler used when training the text encoder.
                            Options: linear, cosine, cosine_with_restarts,
                            polynomial, constant, constant_with_warmup
                          default: linear
                        text_8_bit_adam:
                          type: boolean
                          description: Enable 8-bit-adam
                          default: false
                        unet_seed:
                          type: integer
                          description: The seed used for training the UNet.
                          default: 555
                          format: int32
                        unet_batch_size:
                          type: integer
                          description: |
                            The number of images that are passed through in a
                            single training step.
                          default: 1
                          format: int32
                        unet_resolution:
                          type: integer
                          description: The resolution at which the UNet is trained.
                          default: 512
                          format: int32
                        unet_epochs:
                          type: integer
                          description: |
                            The number of epochs used when training the UNet,
                            the number of steps are extrapolated by multiplying
                            the number of input images by the epochs. For
                            example, if you choose 100 unet_epochs and have 6
                            input pictures, then your job will be 600 steps
                            total (6 x 100)
                          default: 150
                          format: int32
                        unet_learning_rate:
                          type: number
                          description: The learning rate when training the UNet.
                          default: 0.000002
                          format: float
                        unet_lr_scheduler:
                          type: string
                          description: |
                            The scheduler used when training the UNet ext
                            encoder. Options: linear, cosine,
                            cosine_with_restarts, polynomial, constant,
                            constant_with_warmup
                          default: linear
                        unet_8_bit_adam:
                          type: boolean
                          description: Enable 8-bit-adam for UNet.
                          default: false
                      required:
                        - data_url
                      type: object
                    inference:
                      type: array
                      description: A list of inference prompts to generate images from.
                      items:
                        properties:
                          enable_hr:
                            type: boolean
                            description: Toggle for hires fix.
                            default: false
                          denoising_strength:
                            type: integer
                            description: The amount of denoising applied to the image.
                            default: 0
                            format: int32
                          firstphase_width:
                            type: integer
                            format: int32
                          firstphase_height:
                            type: integer
                            format: int32
                          hr_scale:
                            type: integer
                            format: int32
                          hr_upscaler:
                            type: string
                          hr_second_pass_steps:
                            type: integer
                            format: int32
                          hr_resize_x:
                            type: integer
                            format: int32
                          hr_resize_y:
                            type: string
                          prompt:
                            type: string
                            description: |
                              The prompt that is used for the generation of the
                              image.
                          styles:
                            type: array
                            default: []
                            items:
                              type: string
                          seed:
                            type: integer
                            format: int32
                          subseed:
                            type: integer
                            format: int32
                          subseed_strength:
                            type: integer
                            format: int32
                          seed_resize_from_h:
                            type: integer
                            format: int32
                          seed_resized_from_w:
                            type: integer
                            format: int32
                          sampler_name:
                            type: string
                            default: Euler a
                            enum:
                              - Euler a
                              - Euler
                              - LMS
                              - Heun
                              - DPM2
                              - DPM2 a
                              - DPM++ 2S a
                              - DPM++ 2M
                              - DPM++ SDE
                              - DPM fast
                              - DPM adaptive
                              - DPM2 Karras
                              - DPM2 a Karras
                              - DPM++ 2S a Karras
                              - DPM++ 2M Karras
                              - DPM++ SDE Karras
                          batch_size:
                            type: integer
                            format: int32
                          n_iter:
                            type: integer
                            format: int32
                          steps:
                            type: integer
                            format: int32
                          cfg_scale:
                            type: integer
                            format: int32
                          width:
                            type: integer
                            format: int32
                          height:
                            type: integer
                            format: int32
                          restore_faces:
                            type: boolean
                          tiling:
                            type: boolean
                          negative_prompt:
                            type: string
                          eta:
                            type: integer
                            format: int32
                          s_churn:
                            type: integer
                            format: int32
                          s_tmax:
                            type: integer
                            format: int32
                          s_tmin:
                            type: integer
                            format: int32
                          s_noise:
                            type: string
                          sampler_index:
                            type: integer
                            format: int32
                          script_name:
                            type: string
                          passback:
                            type: string
                        type: object
                  required: []
                  type: object
                  description: |
                    Input object containing your training parameters, optional
                    inference parameters, optional S3 bucket, and optional
                    webhook.
                webhook:
                  type: string
                  description: |
                    URL endpoint to receive a webhook call on job complete,
                    fail, or timeout.
                s3Config:
                  properties:
                    bucketName:
                      type: string
                      description: Bucket where you would like the model to be stored.
                      default: job_id
                    accessId:
                      type: string
                      description: The ID required for your S3 bucket.
                    accessSecret:
                      type: string
                      description: The secret required for your S3 bucket.
                    endpointUrl:
                      type: string
                      description: The URL for your S3 bucket.
                  required:
                    - bucketName
                    - accessId
                    - accessSecret
                    - endpointUrl
                  type: object
                  description: |
                    Credentials for a user-defined S3 compatible bucket where
                    the trained model can be uploaded to.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |-
                    {
                    "id": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
                    "status": "IN_QUEUE"
                    }
              schema:
                type: object
                properties:
                  id:
                    type: string
                    example: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
                  status:
                    type: string
                    example: IN_QUEUE
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '401':
          description: '401'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
        '429':
          description: '429'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
      deprecated: false
  /gpt-neo-1_3b/{run_type}:
    post:
      summary: GPT Neo 1.3B
      description: |
        GPT-Neo 1.3B is a transformer model designed using EleutherAI's
        replication of the GPT-3 architecture.
      operationId: neo-13b
      parameters:
        - name: run_type
          in: path
          description: |
            Decides whether to run this asynchronously or synchronously. If you
            use "run", then it will be run async and you must use the "Receive
            Output/Status" endpoint with the run id to get your result.
          schema:
            type: string
            enum:
              - runsync
              - run
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      description: |
                        The start of the prompt text that the model will infer
                        from.
                      default: |
                        Why, sometimes I've believed as many as six impossible
                        things
                    do_sample:
                      type: boolean
                      description: |
                        Enables decoding strategies such as multinomial
                        sampling, beam-search multinomial sampling, Top-K
                        sampling and Top-p sampling. All these strategies select
                        the next token from the probability distribution over
                        the entire vocabulary with various strategy-specific
                        adjustments.
                      default: false
                    max_length:
                      type: integer
                      description: The number of tokens to generate in one output.
                      default: 100
                      format: int32
                    temperature:
                      type: number
                      description: How closely should the output match the prompt.
                      default: 0.9
                      format: float
                  required:
                    - prompt
                  type: object
                  description: Inputs to be generated.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                runsync:
                  value: |
                    {

                    "delayTime": 8,

                    "executionTime": 4572,

                    "id": "sync-9c573aaa-f3ef-46d2-879c-44262c8876ca",

                    "output": "Why, sometimes I've believed as many as six
                    impossible things before breakfast.\" \"I don't know why I'm
                    telling you all this.\" \"I just do.\" \"I'm not a very good
                    liar.\" \"I'm not a very good anything.\" \"I'm not a very
                    good anything.\" \"I'm not a very good anything.\" \"I'm not
                    a very good anything.\" \"I'm not a very good anything.\"
                    \"I'm not a very good anything.\" \"I'm not",

                    "status": "COMPLETED"

                    }
                run:
                  value: |-
                    {
                    "id": "9c6ed893-fda5-4ea6-9e0a-82af9a82403c",
                    "status": "IN_QUEUE"
                    }
              schema:
                oneOf:
                  - title: runsync
                    type: object
                    properties:
                      delayTime:
                        type: integer
                        example: 8
                        default: 0
                      executionTime:
                        type: integer
                        example: 4572
                        default: 0
                      id:
                        type: string
                        example: sync-9c573aaa-f3ef-46d2-879c-44262c8876ca
                      output:
                        type: string
                        example: |
                          Why, sometimes I've believed as many as six impossible
                          things before breakfast." "I don't know why I'm
                          telling you all this." "I just do." "I'm not a very
                          good liar." "I'm not a very good anything." "I'm not a
                          very good anything." "I'm not a very good anything."
                          "I'm not a very good anything." "I'm not a very good
                          anything." "I'm not a very good anything." "I'm not
                      status:
                        type: string
                        example: COMPLETED
                  - title: run
                    type: object
                    properties:
                      id:
                        type: string
                        example: 9c6ed893-fda5-4ea6-9e0a-82af9a82403c
                      status:
                        type: string
                        example: IN_QUEUE
      deprecated: false
  /gpt-neox-20b/{method}:
    post:
      summary: GPT NeoX 20B
      description: ''
      operationId: neox-20b
      parameters:
        - name: method
          in: path
          description: |
            Decides whether to run this asynchronously or synchronously. If you
            use "run", then it will be run async and you must use the "Receive
            Output/Status" endpoint with the run id to get your result.
          schema:
            type: string
            enum:
              - runsync
              - sync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      description: |
                        The start of the prompt text that the model will infer
                        from.
                      default: |
                        Why, sometimes I've believed as many as six impossible
                        things
                    do_sample:
                      type: boolean
                      description: |
                        Enables decoding strategies such as multinomial
                        sampling, beam-search multinomial sampling, Top-K
                        sampling and Top-p sampling. All these strategies select
                        the next token from the probability distribution over
                        the entire vocabulary with various strategy-specific
                        adjustments.
                      default: false
                    max_length:
                      type: integer
                      description: The number of tokens to generate in one output.
                      default: 100
                      format: int32
                    temperature:
                      type: number
                      description: How closely should the output match the prompt.
                      default: 0.9
                      format: float
                  required:
                    - prompt
                  type: object
                  description: Inputs to be generated.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                runsync:
                  value: |
                    {

                    "delayTime": 8,

                    "executionTime": 4572,

                    "id": "sync-9c573aaa-f3ef-46d2-879c-44262c8876ca",

                    "output": "Why, sometimes I've believed as many as six
                    impossible things before breakfast.\" \"I don't know why I'm
                    telling you all this.\" \"I just do.\" \"I'm not a very good
                    liar.\" \"I'm not a very good anything.\" \"I'm not a very
                    good anything.\" \"I'm not a very good anything.\" \"I'm not
                    a very good anything.\" \"I'm not a very good anything.\"
                    \"I'm not a very good anything.\" \"I'm not",

                    "status": "COMPLETED"

                    }
                run:
                  value: |-
                    {
                    "id": "9c6ed893-fda5-4ea6-9e0a-82af9a82403c",
                    "status": "IN_QUEUE"
                    }
              schema:
                oneOf:
                  - title: runsync
                    type: object
                    properties:
                      delayTime:
                        type: integer
                        example: 8
                        default: 0
                      executionTime:
                        type: integer
                        example: 4572
                        default: 0
                      id:
                        type: string
                        example: sync-9c573aaa-f3ef-46d2-879c-44262c8876ca
                      output:
                        type: string
                        example: |
                          Why, sometimes I've believed as many as six impossible
                          things before breakfast." "I don't know why I'm
                          telling you all this." "I just do." "I'm not a very
                          good liar." "I'm not a very good anything." "I'm not a
                          very good anything." "I'm not a very good anything."
                          "I'm not a very good anything." "I'm not a very good
                          anything." "I'm not a very good anything." "I'm not
                      status:
                        type: string
                        example: COMPLETED
                  - title: run
                    type: object
                    properties:
                      id:
                        type: string
                        example: 9c6ed893-fda5-4ea6-9e0a-82af9a82403c
                      status:
                        type: string
                        example: IN_QUEUE
      deprecated: false
  /pygmalion-6b/{run_type}:
    post:
      summary: Pygmalion 6B
      description: ''
      operationId: pygmalion-6b
      parameters:
        - name: run_type
          in: path
          description: |
            Decides whether to run this asynchronously or synchronously. If you
            use "run", then it will be run async and you must use the "Receive
            Output/Status" endpoint with the run id to get your result.
          schema:
            type: string
            enum:
              - runsync
              - run
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      description: |
                        The start of the prompt text that the model will infer
                        from.
                      default: |
                        Why, sometimes I've believed as many as six impossible
                        things
                    do_sample:
                      type: boolean
                      description: |
                        Enables decoding strategies such as multinomial
                        sampling, beam-search multinomial sampling, Top-K
                        sampling and Top-p sampling. All these strategies select
                        the next token from the probability distribution over
                        the entire vocabulary with various strategy-specific
                        adjustments.
                      default: false
                    max_length:
                      type: integer
                      description: The number of tokens to generate in one output.
                      default: 100
                      format: int32
                    temperature:
                      type: number
                      description: How closely should the output match the prompt.
                      default: 0.9
                      format: float
                  required:
                    - prompt
                  type: object
                  description: Inputs to be generated.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                runsync:
                  value: |
                    {

                    "delayTime": 8,

                    "executionTime": 4572,

                    "id": "sync-9c573aaa-f3ef-46d2-879c-44262c8876ca",

                    "output": "Why, sometimes I've believed as many as six
                    impossible things before breakfast.\" \"I don't know why I'm
                    telling you all this.\" \"I just do.\" \"I'm not a very good
                    liar.\" \"I'm not a very good anything.\" \"I'm not a very
                    good anything.\" \"I'm not a very good anything.\" \"I'm not
                    a very good anything.\" \"I'm not a very good anything.\"
                    \"I'm not a very good anything.\" \"I'm not",

                    "status": "COMPLETED"

                    }
                run:
                  value: |-
                    {
                    "id": "9c6ed893-fda5-4ea6-9e0a-82af9a82403c",
                    "status": "IN_QUEUE"
                    }
              schema:
                oneOf:
                  - title: runsync
                    type: object
                    properties:
                      delayTime:
                        type: integer
                        example: 8
                        default: 0
                      executionTime:
                        type: integer
                        example: 4572
                        default: 0
                      id:
                        type: string
                        example: sync-9c573aaa-f3ef-46d2-879c-44262c8876ca
                      output:
                        type: string
                        example: |
                          Why, sometimes I've believed as many as six impossible
                          things before breakfast." "I don't know why I'm
                          telling you all this." "I just do." "I'm not a very
                          good liar." "I'm not a very good anything." "I'm not a
                          very good anything." "I'm not a very good anything."
                          "I'm not a very good anything." "I'm not a very good
                          anything." "I'm not a very good anything." "I'm not
                      status:
                        type: string
                        example: COMPLETED
                  - title: run
                    type: object
                    properties:
                      id:
                        type: string
                        example: 9c6ed893-fda5-4ea6-9e0a-82af9a82403c
                      status:
                        type: string
                        example: IN_QUEUE
      deprecated: false
  /gpt-neo-2_7b/{run_type}:
    post:
      summary: GPT Neo 2.7B
      description: ''
      operationId: neo-27b
      parameters:
        - name: run_type
          in: path
          description: |
            Decides whether to run this asynchronously or synchronously. If you
            use "run", then it will be run async and you must use the "Receive
            Output/Status" endpoint with the run id to get your result.
          schema:
            type: string
            enum:
              - runsync
              - run
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      description: |
                        The start of the prompt text that the model will infer
                        from.
                      default: |
                        Why, sometimes I've believed as many as six impossible
                        things
                    do_sample:
                      type: boolean
                      description: |
                        Enables decoding strategies such as multinomial
                        sampling, beam-search multinomial sampling, Top-K
                        sampling and Top-p sampling. All these strategies select
                        the next token from the probability distribution over
                        the entire vocabulary with various strategy-specific
                        adjustments.
                      default: false
                    max_length:
                      type: integer
                      description: The number of tokens to generate in one output.
                      default: 100
                      format: int32
                    temperature:
                      type: number
                      description: How closely should the output match the prompt.
                      default: 0.9
                      format: float
                  required:
                    - prompt
                  type: object
                  description: Inputs to be generated.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                runsync:
                  value: |
                    {

                    "delayTime": 8,

                    "executionTime": 4572,

                    "id": "sync-9c573aaa-f3ef-46d2-879c-44262c8876ca",

                    "output": "Why, sometimes I've believed as many as six
                    impossible things before breakfast.\" \"I don't know why I'm
                    telling you all this.\" \"I just do.\" \"I'm not a very good
                    liar.\" \"I'm not a very good anything.\" \"I'm not a very
                    good anything.\" \"I'm not a very good anything.\" \"I'm not
                    a very good anything.\" \"I'm not a very good anything.\"
                    \"I'm not a very good anything.\" \"I'm not",

                    "status": "COMPLETED"

                    }
                run:
                  value: |-
                    {
                    "id": "9c6ed893-fda5-4ea6-9e0a-82af9a82403c",
                    "status": "IN_QUEUE"
                    }
              schema:
                oneOf:
                  - title: runsync
                    type: object
                    properties:
                      delayTime:
                        type: integer
                        example: 8
                        default: 0
                      executionTime:
                        type: integer
                        example: 4572
                        default: 0
                      id:
                        type: string
                        example: sync-9c573aaa-f3ef-46d2-879c-44262c8876ca
                      output:
                        type: string
                        example: |
                          Why, sometimes I've believed as many as six impossible
                          things before breakfast." "I don't know why I'm
                          telling you all this." "I just do." "I'm not a very
                          good liar." "I'm not a very good anything." "I'm not a
                          very good anything." "I'm not a very good anything."
                          "I'm not a very good anything." "I'm not a very good
                          anything." "I'm not a very good anything." "I'm not
                      status:
                        type: string
                        example: COMPLETED
                  - title: run
                    type: object
                    properties:
                      id:
                        type: string
                        example: 9c6ed893-fda5-4ea6-9e0a-82af9a82403c
                      status:
                        type: string
                        example: IN_QUEUE
      deprecated: false
  /{MODEL_ID}/status/{RUN_ID}:
    get:
      summary: Receive Output/Status
      description: ''
      operationId: receive-outputstatus
      parameters:
        - name: MODEL_ID
          in: path
          schema:
            type: string
            enum:
              - gpt-neo-1_3b
              - gpt-neo-2_7b
              - gpt-neox-20b
              - pygmalion-6b
          required: true
        - name: RUN_ID
          in: path
          schema:
            type: string
          required: true
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /gpt-j-6b/{method}:
    post:
      summary: GPT-J 6B
      description: ''
      operationId: gpt-j-6b
      parameters:
        - name: method
          in: path
          description: |
            Decides whether to run this asynchronously or synchronously. If you
            use "run", then it will be run async and you must use the "Receive
            Output/Status" endpoint with the run id to get your result.
          schema:
            type: string
            enum:
              - runsync
              - run
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      description: |
                        The start of the prompt text that the model will infer
                        from.
                      default: |
                        Why, sometimes I've believed as many as six impossible
                        things
                    do_sample:
                      type: boolean
                      description: |
                        Enables decoding strategies such as multinomial
                        sampling, beam-search multinomial sampling, Top-K
                        sampling and Top-p sampling. All these strategies select
                        the next token from the probability distribution over
                        the entire vocabulary with various strategy-specific
                        adjustments.
                      default: false
                    max_length:
                      type: integer
                      description: The number of tokens to generate in one output.
                      default: 100
                      format: int32
                    temperature:
                      type: number
                      description: How closely should the output match the prompt.
                      default: 0.9
                      format: float
                  required:
                    - prompt
                  type: object
                  description: Inputs to be generated.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                runsync:
                  value: |
                    {

                    "delayTime": 8,

                    "executionTime": 4572,

                    "id": "sync-9c573aaa-f3ef-46d2-879c-44262c8876ca",

                    "output": "Why, sometimes I've believed as many as six
                    impossible things before breakfast.\" \"I don't know why I'm
                    telling you all this.\" \"I just do.\" \"I'm not a very good
                    liar.\" \"I'm not a very good anything.\" \"I'm not a very
                    good anything.\" \"I'm not a very good anything.\" \"I'm not
                    a very good anything.\" \"I'm not a very good anything.\"
                    \"I'm not a very good anything.\" \"I'm not",

                    "status": "COMPLETED"

                    }
                run:
                  value: |-
                    {
                    "id": "9c6ed893-fda5-4ea6-9e0a-82af9a82403c",
                    "status": "IN_QUEUE"
                    }
              schema:
                oneOf:
                  - title: runsync
                    type: object
                    properties:
                      delayTime:
                        type: integer
                        example: 8
                        default: 0
                      executionTime:
                        type: integer
                        example: 4572
                        default: 0
                      id:
                        type: string
                        example: sync-9c573aaa-f3ef-46d2-879c-44262c8876ca
                      output:
                        type: string
                        example: |
                          Why, sometimes I've believed as many as six impossible
                          things before breakfast." "I don't know why I'm
                          telling you all this." "I just do." "I'm not a very
                          good liar." "I'm not a very good anything." "I'm not a
                          very good anything." "I'm not a very good anything."
                          "I'm not a very good anything." "I'm not a very good
                          anything." "I'm not a very good anything." "I'm not
                      status:
                        type: string
                        example: COMPLETED
                  - title: run
                    type: object
                    properties:
                      id:
                        type: string
                        example: 9c6ed893-fda5-4ea6-9e0a-82af9a82403c
                      status:
                        type: string
                        example: IN_QUEUE
      deprecated: false
  /everydream-v1/run:
    post:
      summary: EveryDream (SD-v1.5)
      description: |
        EveryDream provides general fine-tuning for Stable Diffusion. This
        endpoint also provides inference so that models can be trained and
        images can be generated in one shot.
      operationId: everydream-sd-v15
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /whisper/{run_type}:
    post:
      summary: Whisper
      description: Whisper is an automatic speech recognition (ASR) system.
      operationId: whisper
      parameters:
        - name: run_type
          in: path
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    audio:
                      type: string
                      description: The URL of the input audio file.
                      default: |
                        https://github.com/runpod-workers/sample-inputs/raw/main/audio/gettysburg.wav
                    model:
                      type: string
                      description: |
                        Choose a Whisper model. Options: tiny, base, small,
                        medium, large-v1, large-v2
                      default: base
                    transcription:
                      type: string
                      description: |
                        Choose the format for the transcription. Options: plain
                        text, srt, vtt
                      default: plain text
                    translate:
                      type: boolean
                      description: Translate the text to English when set to True.
                      default: false
                    language:
                      type: string
                      description: |
                        Language spoken in the audio, specify None to perform
                        language detection.
                      default: en
                    temperature:
                      type: number
                      description: Temperature to use for sampling.
                      default: 0
                      format: float
                    best_of:
                      type: integer
                      description: |
                        The number of candidates when sampling with non-zero
                        temperature.
                      default: 5
                      format: int32
                    beam_size:
                      type: integer
                      description: |
                        Number of beams in beam search, only applicable when
                        temperature is zero.
                      default: 5
                      format: int32
                    patience:
                      type: number
                      description: Optional patience value to use in beam decoding.
                      default: 1
                      format: float
                    suppress_tokens:
                      type: string
                      description: |
                        Comma-separated list of token ids to suppress during
                        sampling; '-1' will suppress most special characters
                        except common punctuations.
                      default: '-1'
                    length_penalty:
                      type: number
                      description: |
                        Optional token length penalty coefficient (alpha). Uses
                        simple length normalization by default.
                      format: float
                    initial_prompt:
                      type: string
                      description: |
                        Optional text to provide as a prompt for the first
                        window.
                      default: None
                    condition_on_previous_text:
                      type: boolean
                      description: |
                        If True, provide the previous output of the model as a
                        prompt for the next window; disabling may make the text
                        inconsistent across windows, but the model becomes less
                        prone to getting stuck in a failure loop.
                      default: false
                    temperature_increment_on_fallback:
                      type: number
                      description: |
                        Temperature to increase when falling back when the
                        decoding fails to meet either of the thresholds below.
                      default: 0.2
                      format: float
                    compression_ratio_threshold:
                      type: number
                      description: |
                        If the gzip compression ration is higher than this
                        value, treat the decoding as failed.
                      default: 2.4
                      format: float
                    logprob_threshold:
                      type: number
                      description: |
                        If the average log probability is lower than this value,
                        treat the decoding as failed.
                      default: -1
                      format: float
                    no_speech_threshold:
                      type: number
                      description: |
                        If the probability of the <|nospeech|> token is higher
                        than this value AND the decoding has failed due to
                        'logprob_threshold', consider the segment as silence.
                      default: 0.6
                      format: float
                  required:
                    - audio
                  type: object
                  description: Input that contains prompts and more.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |-
                    {
                    "id": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
                    "status": "IN_QUEUE"
                    }
              schema:
                type: object
                properties:
                  id:
                    type: string
                    example: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
                  status:
                    type: string
                    example: IN_QUEUE
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '401':
          description: '401'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
        '429':
          description: '429'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
      deprecated: false
  /controlnet-depth/{run_type}:
    post:
      summary: Depth
      description: This page will help you get started with ControlNet - Depth.
      operationId: depth
      parameters:
        - name: run_type
          in: path
          description: |
            Run type, run returns a job ID and runsync returns the results in
            the same call if completed within 30 seconds.
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    image_url:
                      type: string
                      description: |
                        The URL for a publicly accessible image to be used as
                        the input.
                    image_base_64:
                      type: string
                      description: An input image in the format of base64.
                    prompt:
                      type: string
                      description: |
                        The prompt to be used to generate an image from, using
                        the source image as a guide.
                    a_prompt:
                      type: string
                      description: Additional text to be appended to prompt.
                      default: best quality, extremely detailed
                    n_prompt:
                      type: string
                      description: |
                        Negative prompt, things that you want to avoid in the
                        output image.
                      default: |
                        longbody, lowres, bad anatomy, bad hands, missing
                        fingers, extra digit, fewer digits, cropped, worst
                        quality, low quality
                    num_samples:
                      type: integer
                      description: |
                        Number of samples (higher values may OOM). Options:
                        ['1', '4']
                      default: 1
                      format: int32
                    image_resolution:
                      type: integer
                      description: |
                        Image resolution to be generated. Options: ['256',
                        '512', '768']
                      default: 512
                      format: int32
                    ddim_steps:
                      type: integer
                      description: Steps
                      default: 20
                      format: int32
                    scale:
                      type: number
                      description: 'Scale for classifier-free guidance. Options: 0.1 -> 30.0'
                      default: 9
                      format: float
                    seed:
                      type: integer
                      description: Seed for reproducibility.
                      default: null
                      format: int32
                    eta:
                      type: number
                      description: |
                        Controls the amount of noise that is added to the input
                        data during the denoising diffusion process. Higher
                        value -> more noise
                      default: 0
                      format: float
                    low_threshold:
                      type: integer
                      default: 100
                      format: int32
                    high_threshold:
                      type: integer
                      default: 200
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: The input parameters that can be used by ControlNet Canny.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |
                    {

                    "delayTime": 199231,

                    "executionTime": 10337,

                    "id": "73a50b0f-844c-4028-a2d2-946c8f0cf584",

                    "input": {

                    "image_url":
                    "https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg",

                    "prompt": "A frog performing yoga."

                    },

                    "output":
                    "https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2",

                    "status": "COMPLETED"

                    }
              schema:
                type: object
                properties:
                  delayTime:
                    type: integer
                    example: 199231
                    default: 0
                  executionTime:
                    type: integer
                    example: 10337
                    default: 0
                  id:
                    type: string
                    example: 73a50b0f-844c-4028-a2d2-946c8f0cf584
                  input:
                    type: object
                    properties:
                      image_url:
                        type: string
                        example: |
                          https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg
                      prompt:
                        type: string
                        example: A frog performing yoga.
                  output:
                    type: string
                    example: |
                      https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2
                  status:
                    type: string
                    example: COMPLETED
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /controlnet-hed/{run_type}:
    post:
      summary: Hed
      description: This page will help you get started with ControlNet - Hed.
      operationId: hed
      parameters:
        - name: run_type
          in: path
          description: |
            Run type, run returns a job ID and runsync returns the results in
            the same call if completed within 30 seconds.
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    image_url:
                      type: string
                      description: |
                        The URL for a publicly accessible image to be used as
                        the input.
                    image_base_64:
                      type: string
                      description: An input image in the format of base64.
                    prompt:
                      type: string
                      description: |
                        The prompt to be used to generate an image from, using
                        the source image as a guide.
                    a_prompt:
                      type: string
                      description: Additional text to be appended to prompt.
                      default: best quality, extremely detailed
                    n_prompt:
                      type: string
                      description: |
                        Negative prompt, things that you want to avoid in the
                        output image.
                      default: |
                        longbody, lowres, bad anatomy, bad hands, missing
                        fingers, extra digit, fewer digits, cropped, worst
                        quality, low quality
                    num_samples:
                      type: integer
                      description: |
                        Number of samples (higher values may OOM). Options:
                        ['1', '4']
                      default: 1
                      format: int32
                    image_resolution:
                      type: integer
                      description: |
                        Image resolution to be generated. Options: ['256',
                        '512', '768']
                      default: 512
                      format: int32
                    ddim_steps:
                      type: integer
                      description: Steps
                      default: 20
                      format: int32
                    scale:
                      type: number
                      description: 'Scale for classifier-free guidance. Options: 0.1 -> 30.0'
                      default: 9
                      format: float
                    seed:
                      type: integer
                      description: Seed for reproducibility.
                      default: null
                      format: int32
                    eta:
                      type: number
                      description: |
                        Controls the amount of noise that is added to the input
                        data during the denoising diffusion process. Higher
                        value -> more noise
                      default: 0
                      format: float
                    low_threshold:
                      type: integer
                      default: 100
                      format: int32
                    high_threshold:
                      type: integer
                      default: 200
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: The input parameters that can be used by ControlNet Canny.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |
                    {

                    "delayTime": 199231,

                    "executionTime": 10337,

                    "id": "73a50b0f-844c-4028-a2d2-946c8f0cf584",

                    "input": {

                    "image_url":
                    "https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg",

                    "prompt": "A frog performing yoga."

                    },

                    "output":
                    "https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2",

                    "status": "COMPLETED"

                    }
              schema:
                type: object
                properties:
                  delayTime:
                    type: integer
                    example: 199231
                    default: 0
                  executionTime:
                    type: integer
                    example: 10337
                    default: 0
                  id:
                    type: string
                    example: 73a50b0f-844c-4028-a2d2-946c8f0cf584
                  input:
                    type: object
                    properties:
                      image_url:
                        type: string
                        example: |
                          https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg
                      prompt:
                        type: string
                        example: A frog performing yoga.
                  output:
                    type: string
                    example: |
                      https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2
                  status:
                    type: string
                    example: COMPLETED
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /controlnet-normal/{run_type}:
    post:
      summary: Normal
      description: This page will help you get started with ControlNet - Normal.
      operationId: normal
      parameters:
        - name: run_type
          in: path
          description: |
            Run type, run returns a job ID and runsync returns the results in
            the same call if completed within 30 seconds.
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    image_url:
                      type: string
                      description: |
                        The URL for a publicly accessible image to be used as
                        the input.
                    image_base_64:
                      type: string
                      description: An input image in the format of base64.
                    prompt:
                      type: string
                      description: |
                        The prompt to be used to generate an image from, using
                        the source image as a guide.
                    a_prompt:
                      type: string
                      description: Additional text to be appended to prompt.
                      default: best quality, extremely detailed
                    n_prompt:
                      type: string
                      description: |
                        Negative prompt, things that you want to avoid in the
                        output image.
                      default: |
                        longbody, lowres, bad anatomy, bad hands, missing
                        fingers, extra digit, fewer digits, cropped, worst
                        quality, low quality
                    num_samples:
                      type: integer
                      description: |
                        Number of samples (higher values may OOM). Options:
                        ['1', '4']
                      default: 1
                      format: int32
                    image_resolution:
                      type: integer
                      description: |
                        Image resolution to be generated. Options: ['256',
                        '512', '768']
                      default: 512
                      format: int32
                    ddim_steps:
                      type: integer
                      description: Steps
                      default: 20
                      format: int32
                    scale:
                      type: number
                      description: 'Scale for classifier-free guidance. Options: 0.1 -> 30.0'
                      default: 9
                      format: float
                    seed:
                      type: integer
                      description: Seed for reproducibility.
                      default: null
                      format: int32
                    eta:
                      type: number
                      description: |
                        Controls the amount of noise that is added to the input
                        data during the denoising diffusion process. Higher
                        value -> more noise
                      default: 0
                      format: float
                    low_threshold:
                      type: integer
                      default: 100
                      format: int32
                    high_threshold:
                      type: integer
                      default: 200
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: The input parameters that can be used by ControlNet Canny.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |
                    {

                    "delayTime": 199231,

                    "executionTime": 10337,

                    "id": "73a50b0f-844c-4028-a2d2-946c8f0cf584",

                    "input": {

                    "image_url":
                    "https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg",

                    "prompt": "A frog performing yoga."

                    },

                    "output":
                    "https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2",

                    "status": "COMPLETED"

                    }
              schema:
                type: object
                properties:
                  delayTime:
                    type: integer
                    example: 199231
                    default: 0
                  executionTime:
                    type: integer
                    example: 10337
                    default: 0
                  id:
                    type: string
                    example: 73a50b0f-844c-4028-a2d2-946c8f0cf584
                  input:
                    type: object
                    properties:
                      image_url:
                        type: string
                        example: |
                          https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg
                      prompt:
                        type: string
                        example: A frog performing yoga.
                  output:
                    type: string
                    example: |
                      https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2
                  status:
                    type: string
                    example: COMPLETED
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /controlnet-mlsd/{run_type}:
    post:
      summary: MLSD
      description: This page will help you get started with ControlNet - MLSD.
      operationId: mlsd
      parameters:
        - name: run_type
          in: path
          description: |
            Run type, run returns a job ID and runsync returns the results in
            the same call if completed within 30 seconds.
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    image_url:
                      type: string
                      description: |
                        The URL for a publicly accessible image to be used as
                        the input.
                    image_base_64:
                      type: string
                      description: An input image in the format of base64.
                    prompt:
                      type: string
                      description: |
                        The prompt to be used to generate an image from, using
                        the source image as a guide.
                    a_prompt:
                      type: string
                      description: Additional text to be appended to prompt.
                      default: best quality, extremely detailed
                    n_prompt:
                      type: string
                      description: |
                        Negative prompt, things that you want to avoid in the
                        output image.
                      default: |
                        longbody, lowres, bad anatomy, bad hands, missing
                        fingers, extra digit, fewer digits, cropped, worst
                        quality, low quality
                    num_samples:
                      type: integer
                      description: |
                        Number of samples (higher values may OOM). Options:
                        ['1', '4']
                      default: 1
                      format: int32
                    image_resolution:
                      type: integer
                      description: |
                        Image resolution to be generated. Options: ['256',
                        '512', '768']
                      default: 512
                      format: int32
                    ddim_steps:
                      type: integer
                      description: Steps
                      default: 20
                      format: int32
                    scale:
                      type: number
                      description: 'Scale for classifier-free guidance. Options: 0.1 -> 30.0'
                      default: 9
                      format: float
                    seed:
                      type: integer
                      description: Seed for reproducibility.
                      default: null
                      format: int32
                    eta:
                      type: number
                      description: |
                        Controls the amount of noise that is added to the input
                        data during the denoising diffusion process. Higher
                        value -> more noise
                      default: 0
                      format: float
                    low_threshold:
                      type: integer
                      default: 100
                      format: int32
                    high_threshold:
                      type: integer
                      default: 200
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: The input parameters that can be used by ControlNet Canny.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |
                    {

                    "delayTime": 199231,

                    "executionTime": 10337,

                    "id": "73a50b0f-844c-4028-a2d2-946c8f0cf584",

                    "input": {

                    "image_url":
                    "https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg",

                    "prompt": "A frog performing yoga."

                    },

                    "output":
                    "https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2",

                    "status": "COMPLETED"

                    }
              schema:
                type: object
                properties:
                  delayTime:
                    type: integer
                    example: 199231
                    default: 0
                  executionTime:
                    type: integer
                    example: 10337
                    default: 0
                  id:
                    type: string
                    example: 73a50b0f-844c-4028-a2d2-946c8f0cf584
                  input:
                    type: object
                    properties:
                      image_url:
                        type: string
                        example: |
                          https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg
                      prompt:
                        type: string
                        example: A frog performing yoga.
                  output:
                    type: string
                    example: |
                      https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2
                  status:
                    type: string
                    example: COMPLETED
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /controlnet-scribble/{run_type}:
    post:
      summary: Scribble
      description: This page will help you get started with ControlNet - Scribble.
      operationId: scribble
      parameters:
        - name: run_type
          in: path
          description: |
            Run type, run returns a job ID and runsync returns the results in
            the same call if completed within 30 seconds.
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    image_url:
                      type: string
                      description: |
                        The URL for a publicly accessible image to be used as
                        the input.
                    image_base_64:
                      type: string
                      description: An input image in the format of base64.
                    prompt:
                      type: string
                      description: |
                        The prompt to be used to generate an image from, using
                        the source image as a guide.
                    a_prompt:
                      type: string
                      description: Additional text to be appended to prompt.
                      default: best quality, extremely detailed
                    n_prompt:
                      type: string
                      description: |
                        Negative prompt, things that you want to avoid in the
                        output image.
                      default: |
                        longbody, lowres, bad anatomy, bad hands, missing
                        fingers, extra digit, fewer digits, cropped, worst
                        quality, low quality
                    num_samples:
                      type: integer
                      description: |
                        Number of samples (higher values may OOM). Options:
                        ['1', '4']
                      default: 1
                      format: int32
                    image_resolution:
                      type: integer
                      description: |
                        Image resolution to be generated. Options: ['256',
                        '512', '768']
                      default: 512
                      format: int32
                    ddim_steps:
                      type: integer
                      description: Steps
                      default: 20
                      format: int32
                    scale:
                      type: number
                      description: 'Scale for classifier-free guidance. Options: 0.1 -> 30.0'
                      default: 9
                      format: float
                    seed:
                      type: integer
                      description: Seed for reproducibility.
                      default: null
                      format: int32
                    eta:
                      type: number
                      description: |
                        Controls the amount of noise that is added to the input
                        data during the denoising diffusion process. Higher
                        value -> more noise
                      default: 0
                      format: float
                    low_threshold:
                      type: integer
                      default: 100
                      format: int32
                    high_threshold:
                      type: integer
                      default: 200
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: The input parameters that can be used by ControlNet Canny.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |
                    {

                    "delayTime": 199231,

                    "executionTime": 10337,

                    "id": "73a50b0f-844c-4028-a2d2-946c8f0cf584",

                    "input": {

                    "image_url":
                    "https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg",

                    "prompt": "A frog performing yoga."

                    },

                    "output":
                    "https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2",

                    "status": "COMPLETED"

                    }
              schema:
                type: object
                properties:
                  delayTime:
                    type: integer
                    example: 199231
                    default: 0
                  executionTime:
                    type: integer
                    example: 10337
                    default: 0
                  id:
                    type: string
                    example: 73a50b0f-844c-4028-a2d2-946c8f0cf584
                  input:
                    type: object
                    properties:
                      image_url:
                        type: string
                        example: |
                          https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg
                      prompt:
                        type: string
                        example: A frog performing yoga.
                  output:
                    type: string
                    example: |
                      https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2
                  status:
                    type: string
                    example: COMPLETED
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /controlnet-seg/{run_type}:
    post:
      summary: Seg
      description: This page will help you get started with ControlNet - Seg.
      operationId: seg
      parameters:
        - name: run_type
          in: path
          description: |
            Run type, run returns a job ID and runsync returns the results in
            the same call if completed within 30 seconds.
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    image_url:
                      type: string
                      description: |
                        The URL for a publicly accessible image to be used as
                        the input.
                    image_base_64:
                      type: string
                      description: An input image in the format of base64.
                    prompt:
                      type: string
                      description: |
                        The prompt to be used to generate an image from, using
                        the source image as a guide.
                    a_prompt:
                      type: string
                      description: Additional text to be appended to prompt.
                      default: best quality, extremely detailed
                    n_prompt:
                      type: string
                      description: |
                        Negative prompt, things that you want to avoid in the
                        output image.
                      default: |
                        longbody, lowres, bad anatomy, bad hands, missing
                        fingers, extra digit, fewer digits, cropped, worst
                        quality, low quality
                    num_samples:
                      type: integer
                      description: |
                        Number of samples (higher values may OOM). Options:
                        ['1', '4']
                      default: 1
                      format: int32
                    image_resolution:
                      type: integer
                      description: |
                        Image resolution to be generated. Options: ['256',
                        '512', '768']
                      default: 512
                      format: int32
                    ddim_steps:
                      type: integer
                      description: Steps
                      default: 20
                      format: int32
                    scale:
                      type: number
                      description: 'Scale for classifier-free guidance. Options: 0.1 -> 30.0'
                      default: 9
                      format: float
                    seed:
                      type: integer
                      description: Seed for reproducibility.
                      default: null
                      format: int32
                    eta:
                      type: number
                      description: |
                        Controls the amount of noise that is added to the input
                        data during the denoising diffusion process. Higher
                        value -> more noise
                      default: 0
                      format: float
                    low_threshold:
                      type: integer
                      default: 100
                      format: int32
                    high_threshold:
                      type: integer
                      default: 200
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: The input parameters that can be used by ControlNet Canny.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |
                    {

                    "delayTime": 199231,

                    "executionTime": 10337,

                    "id": "73a50b0f-844c-4028-a2d2-946c8f0cf584",

                    "input": {

                    "image_url":
                    "https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg",

                    "prompt": "A frog performing yoga."

                    },

                    "output":
                    "https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2",

                    "status": "COMPLETED"

                    }
              schema:
                type: object
                properties:
                  delayTime:
                    type: integer
                    example: 199231
                    default: 0
                  executionTime:
                    type: integer
                    example: 10337
                    default: 0
                  id:
                    type: string
                    example: 73a50b0f-844c-4028-a2d2-946c8f0cf584
                  input:
                    type: object
                    properties:
                      image_url:
                        type: string
                        example: |
                          https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg
                      prompt:
                        type: string
                        example: A frog performing yoga.
                  output:
                    type: string
                    example: |
                      https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2
                  status:
                    type: string
                    example: COMPLETED
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /controlnet-openpose/{run_type}:
    post:
      summary: Openpose
      description: This page will help you get started with ControlNet - Openpose.
      operationId: openpose
      parameters:
        - name: run_type
          in: path
          description: |
            Run type, run returns a job ID and runsync returns the results in
            the same call if completed within 30 seconds.
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    image_url:
                      type: string
                      description: |
                        The URL for a publicly accessible image to be used as
                        the input.
                    image_base_64:
                      type: string
                      description: An input image in the format of base64.
                    prompt:
                      type: string
                      description: |
                        The prompt to be used to generate an image from, using
                        the source image as a guide.
                    a_prompt:
                      type: string
                      description: Additional text to be appended to prompt.
                      default: best quality, extremely detailed
                    n_prompt:
                      type: string
                      description: |
                        Negative prompt, things that you want to avoid in the
                        output image.
                      default: |
                        longbody, lowres, bad anatomy, bad hands, missing
                        fingers, extra digit, fewer digits, cropped, worst
                        quality, low quality
                    num_samples:
                      type: integer
                      description: |
                        Number of samples (higher values may OOM). Options:
                        ['1', '4']
                      default: 1
                      format: int32
                    image_resolution:
                      type: integer
                      description: |
                        Image resolution to be generated. Options: ['256',
                        '512', '768']
                      default: 512
                      format: int32
                    ddim_steps:
                      type: integer
                      description: Steps
                      default: 20
                      format: int32
                    scale:
                      type: number
                      description: 'Scale for classifier-free guidance. Options: 0.1 -> 30.0'
                      default: 9
                      format: float
                    seed:
                      type: integer
                      description: Seed for reproducibility.
                      default: null
                      format: int32
                    eta:
                      type: number
                      description: |
                        Controls the amount of noise that is added to the input
                        data during the denoising diffusion process. Higher
                        value -> more noise
                      default: 0
                      format: float
                    low_threshold:
                      type: integer
                      default: 100
                      format: int32
                    high_threshold:
                      type: integer
                      default: 200
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: The input parameters that can be used by ControlNet Canny.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |
                    {

                    "delayTime": 199231,

                    "executionTime": 10337,

                    "id": "73a50b0f-844c-4028-a2d2-946c8f0cf584",

                    "input": {

                    "image_url":
                    "https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg",

                    "prompt": "A frog performing yoga."

                    },

                    "output":
                    "https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2",

                    "status": "COMPLETED"

                    }
              schema:
                type: object
                properties:
                  delayTime:
                    type: integer
                    example: 199231
                    default: 0
                  executionTime:
                    type: integer
                    example: 10337
                    default: 0
                  id:
                    type: string
                    example: 73a50b0f-844c-4028-a2d2-946c8f0cf584
                  input:
                    type: object
                    properties:
                      image_url:
                        type: string
                        example: |
                          https://github.com/runpod/serverless-workers/raw/main/Input-Samples/yoga.jpg
                      prompt:
                        type: string
                        example: A frog performing yoga.
                  output:
                    type: string
                    example: |
                      https://14068d66ba387efac9ce5e4b1741bcf2.r2.cloudflarestorage.com/ai-api/03-23/73a50b0f-844c-4028-a2d2-946c8f0cf584/8f53aeef.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=16b502c87564788383d52ec498a61a24%2F20230320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230320T193202Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=7a4df2e610b5556e48c5e300238e8d24e3e4d403770509232f747d9728e4dbf2
                  status:
                    type: string
                    example: COMPLETED
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /kandinsky-v2/{run_type}:
    post:
      summary: Kandinsky 2.1
      description: Combining the best practices from Dall-E 2 and Latent diffusion.
      operationId: kandinsky-21
      parameters:
        - name: run_type
          in: path
          description: |
            Run type, run returns a job ID and runsync returns the results in
            the same call if completed within 30 seconds.
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      description: Your input prompt.
                      default: Einstein in space around the logarithm scheme
                    negative_prompt:
                      type: string
                      description: |
                        This parameter is used to guide the model's decoder
                        network. It provides more specific guidance on what
                        elements or features should be avoided in the image. If
                        this parameter is provided it will set the two other
                        negative parameters to be the same.
                      default: |
                        disfigured mouth, disfigured teeth, half head, half
                        face, blury, side looking, old, wrinkle, child, no face,
                        pencil, full body, sharp, far away, overlapping,
                        duplication, nude, disfigured, kitsch, oversaturated,
                        grain, low-res, Deformed, blurry, bad anatomy, poorly
                        drawn face, mutation, mutated, extra limb, ugly, poorly
                        drawn hands, missing limb, blurry, floating limbs,
                        disconnected limbs, malformed hands, blur, out of focus,
                        long body, disgusting, poorly drawn, childish,
                        mutilated, mangled, surreal, out of frame, duplicate, 2
                        faces
                    negative_prior_prompt:
                      type: string
                      description: |
                        This parameter is used to guide the model's decoder
                        network. It provides more specific guidance on what
                        elements or features should be avoided in the image
                    negative_decoder_prompt:
                      type: string
                      description: |
                        This parameter is used to guide the model's decoder
                        network. It provides more specific guidance on what
                        elements or features should be avoided in the image
                    num_steps:
                      type: integer
                      description: Number of steps for each image.
                      default: 100
                      format: int32
                    guidance_scale:
                      type: number
                      description: The scaling factor for the guidance term in the model.
                      default: 4
                      format: float
                    h:
                      type: integer
                      description: The height of the generated image in pixels.
                      default: 768
                      format: int32
                    w:
                      type: integer
                      description: The width of the generated image in pixels.
                      default: 768
                      format: int32
                    sampler:
                      type: string
                      description: The sampler used during the inference process.
                      default: ddim
                    prior_cf_scale:
                      type: number
                      description: |
                        The scaling factor for the prior counterfactual term in
                        the model. This term helps the model generate images
                        that are consistent with the prior distribution.
                      default: 4
                      format: float
                    prior_steps:
                      type: string
                      description: |
                        The number of steps taken by the prior model during the
                        inference process. A higher number of prior steps may
                        result in more refined output images, but it can also
                        increase the computation time.
                      default: '5'
                    num_images:
                      type: integer
                      description: Number of images to generate in single run
                      default: 1
                      format: int32
                    seed:
                      type: integer
                      description: Seed to use when generating image
                      default: -1
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: Input object contains prompt, and more.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /real-esrgan/{run_type}:
    post:
      summary: Real-ESRGAN
      description: |
        A model that can upscale images using various pre-trained models. You
        can provide a set of parameters to control the upscaling process and
        choose the output format.
      operationId: real-esrgan
      parameters:
        - name: run_type
          in: path
          schema:
            type: string
            enum:
              - run
              - runsync
            default: run
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    data_url:
                      type: string
                      description: |
                        The URL of the input image file or a zip file containing
                        multiple image files.
                    model:
                      type: string
                      description: The pre-trained model to be used for upscaling.
                      default: RealESRGAN_x4plus
                      enum:
                        - RealESRGAN_x4plus
                        - RealESRNet_x4plus
                        - RealESRGAN_x4plus_anime_6B
                        - RealESRGAN_x2plus
                    scale:
                      type: number
                      description: The scale factor for upscaling. Must be between 0 and 4.
                      default: 4
                      format: float
                    tile:
                      type: integer
                      description: The tile size for the upscaling process.
                      default: 0
                      format: int32
                    tile_pad:
                      type: integer
                      description: The padding size for the tiles.
                      default: 10
                      format: int32
                    pre_pad:
                      type: integer
                      description: The padding size before upscaling.
                      default: 0
                      format: int32
                    output_type:
                      type: string
                      description: |
                        The output format for the results. individual: Each
                        image will be stored separately. | zip: All images will
                        be stored in a zip file.
                      default: individual
                      enum:
                        - individual
                        - zip
                  required:
                    - data_url
                  type: object
                  description: Input parameters to make a request to the endpoint.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /{endpoint_id}/health:
    get:
      summary: Health Check
      description: Retrieve endpoint statistics.
      operationId: health-check
      parameters:
        - name: endpoint_id
          in: path
          description: The endpoint you wish to retrieve the health status from.
          schema:
            type: string
            default: stable-diffusion-v1
          required: true
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |-
                    {
                    "jobs": {
                    "inProgress": 0,
                    "inQueue": 0
                    },
                    "workers": {
                    "idle": 0,
                    "running": 0
                    }
                    }
              schema:
                type: object
                properties:
                  jobs:
                    type: object
                    properties:
                      inProgress:
                        type: integer
                        example: 0
                        default: 0
                      inQueue:
                        type: integer
                        example: 0
                        default: 0
                  workers:
                    type: object
                    properties:
                      idle:
                        type: integer
                        example: 0
                        default: 0
                      running:
                        type: integer
                        example: 0
                        default: 0
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /blip/{run_type}:
    post:
      summary: BLIP Captioning
      description: |
        This API allows you to caption zipped images that can be later used for
        Stable Diffusion finetuning (compatible with EveryDream)
      operationId: blip-captioning
      parameters:
        - name: run_type
          in: path
          description: |
            Run type, run returns a job ID and runsync returns the results in
            the same call if completed within 30 seconds.
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    data_url:
                      type: string
                      description: |
                        The URL of the image or zip file containing multiple
                        images to be captioned. The supported image formats are
                        JPEG and PNG.
                      default: |
                        https://github.com/runpod-workers/worker-blip/raw/main/test/froggy.zip
                    max_length:
                      type: integer
                      description: |
                        The maximum length of the generated captions. It should
                        be a positive integer.
                      default: 75
                      format: int32
                    min_length:
                      type: integer
                      description: |
                        The minimum length of the generated captions. It should
                        be a positive integer.
                      default: 5
                      format: int32
                  required:
                    - data_url
                  type: object
                  description: Input object contains prompt, and more.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /faster-whisper/status/{job_id}:
    get:
      summary: Retrieve Results & Status
      description: ''
      operationId: retrieve-results-status
      parameters:
        - name: job_id
          in: path
          description: The job id returned after your /run or /runsync request.
          schema:
            type: string
          required: true
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /deforum/{run_type}:
    post:
      summary: Deforum
      description: ''
      operationId: deforum
      parameters:
        - name: run_type
          in: path
          description: If you want to call the endpoint synonyms or asynchronous.
          schema:
            type: string
            enum:
              - runsync
              - run
            default: run
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    model_checkpoint:
                      type: string
                      description: |
                        Specifies the name of the model checkpoint file to be
                        loaded
                      default: Protogen_V2.2.ckpt
                    max_frames:
                      type: integer
                      description: |
                        Specifies the maximum number of frames that the video
                        will have. More frames mean a longer video, but also a
                        longer render time.
                      default: 200
                      format: int32
                    animation_prompts:
                      type: string
                      description: |
                        Specifies the animation prompts at specific frame
                        numbers. Each prompt influences the content of the
                        animation. Multiple prompts are separated by the "|"
                        symbol, and each prompt is associated with a frame
                        number, separated by ":"
                      default: |
                        0: a beautiful apple, trending on Artstation | 50: a
                        beautiful banana, trending on Artstation | 100: a
                        beautiful coconut, trending on Artstation | 150: a
                        beautiful durian, trending on Artstation
                    negative_prompts:
                      type: string
                      description: |
                        These are the animation prompts that the model will
                        actively avoid in the generated frames. The format for
                        input is similar to the animation_prompts.
                      default: '0: mountain'
                    width:
                      type: integer
                      description: The width of the generated video in pixels
                      default: 512
                      format: int32
                    height:
                      type: integer
                      description: The height of the generated video in pixels
                      default: 512
                      format: int32
                    num_inference_steps:
                      type: integer
                      description: |
                        Specifies the number of inference steps for the model to
                        perform. A higher number may increase the quality of the
                        generated video but will also increase rendering time.
                      default: 50
                      format: int32
                    guidance_scale:
                      type: number
                      description: |
                        This parameter influences the strength of the animation
                        prompts. A higher value leads to stronger influence from
                        the prompts
                      default: 7
                      format: float
                    sampler:
                      type: string
                      description: |
                        Specifies the sampling method to be used. The choice of
                        sampler can influence the dynamics of the generated
                        video.
                      default: euler_ancestral
                    seed:
                      type: integer
                      description: |
                        Defines the random seed for the generation process. If
                        set to a specific integer, the generated video will be
                        the same each time the code is run with that seed.
                      format: int32
                    fps:
                      type: integer
                      description: |
                        Specifies the frames per second (fps) of the generated
                        video. Higher values will result in smoother videos but
                        also longer rendering times.
                      default: 15
                      format: int32
                    clip_name:
                      type: string
                      description: |
                        Specifies the name of the CLIP model variant to be used
                        for generating the video.
                      default: ViT-L/14
                    use_init:
                      type: boolean
                      description: |
                        Determines whether to use an initial image to start the
                        generation process. If True, an initial image needs to
                        be specified using init_image.
                      default: false
                    init_image:
                      type: string
                      description: |
                        Specifies the path to the initial image file to be used
                        if use_init is set to True. The initial image can guide
                        the starting point of the generation process.
                    strength:
                      type: number
                      description: |
                        Sets the strength of the guidance by the prompts. Higher
                        values make the resulting animation adhere more to the
                        prompts.
                      default: 0.5
                      format: float
                    use_mask:
                      type: string
                      description: |
                        If use_mask is set to True, this parameter specifies the
                        path to the mask image file to be used. The mask can
                        influence the area of the image to which the prompts
                        apply.
                    invert_mask:
                      type: boolean
                      description: |
                        If True, the mask specified by mask_file will be
                        inverted. This means that the areas to which the prompts
                        apply will be reversed.
                      default: false
                    animation_mode:
                      type: string
                      description: |
                        Defines the mode of animation for the generated video.
                        Options are 2D or 3D. This influences the type of
                        transformations applied to the video.
                      default: 2D
                    border:
                      type: string
                      description: |
                        Specifies how the border of the animation is handled.
                        This is important when transformations like translation
                        or rotation are applied.
                      default: replicate
                    angle:
                      type: string
                      description: |
                        Defines the angle of rotation for the animation. The
                        string should be formatted as time:(angle). Multiple
                        time points can be specified using a | separator.
                      default: 0:(0)
                    zoom:
                      type: string
                      description: |
                        Specifies the zoom factor for the animation. The string
                        should be formatted as time:(zoom_factor). Multiple time
                        points can be specified using a | separator.
                      default: 0:(1.04)
                    translation_x:
                      type: string
                      description: |
                        Defines the x-direction translation for the animation.
                        The string should be formatted as time:(translation_x).
                        Multiple time points can be specified using a |
                        separator.
                      default: 0:(10*sin(2*3.14*t/10))
                    translation_y:
                      type: string
                      description: |
                        Defines the y-direction translation for the animation.
                        The string should be formatted as time:(translation_y).
                        Multiple time points can be specified using a |
                        separator.
                      default: 0:(0)
                    translation_z:
                      type: string
                      description: |
                        Defines the z-direction translation for the animation.
                        The string should be formatted as time:(translation_z).
                        Multiple time points can be specified using a |
                        separator.
                      default: 0:(10)
                    rotation_3d_x:
                      type: string
                      description: |
                        Defines the x-axis rotation for the 3D animation. The
                        string should be formatted as time:(rotation_angle).
                        Multiple time points can be specified using a |
                        separator.
                      default: 0:(0)
                    rotation_3d_y:
                      type: string
                      description: |
                        Defines the y-axis rotation for the 3D animation. The
                        string should be formatted as time:(rotation_angle).
                        Multiple time points can be specified using a |
                        separator.
                      default: 0:(0)
                    rotation_3d_z:
                      type: string
                      description: |
                        Defines the z-axis rotation for the 3D animation. The
                        string should be formatted as time:(rotation_angle).
                        Multiple time points can be specified using a |
                        separator.
                      default: 0:(0)
                    flip_2d_perspective:
                      type: boolean
                      description: |
                        If True, a 2D perspective flip transformation will be
                        applied to the animation.
                      default: false
                    perspective_flip_theta:
                      type: string
                      description: |
                        Defines the theta angle for the perspective flip. The
                        string should be formatted as time:(angle). Multiple
                        time points can be specified using a | separator.
                      default: 0:(0)
                    perspective_flip_phi:
                      type: string
                      description: |
                        Defines the phi angle for the perspective flip. The
                        string should be formatted as time:(angle). Multiple
                        time points can be specified using a | separator.
                      default: 0:(t%15)
                    perspective_flip_gamma:
                      type: string
                      description: |
                        Defines the gamma angle for the perspective flip. The
                        string should be formatted as time:(angle). Multiple
                        time points can be specified using a | separator.
                      default: 0:(0)
                    perspective_flip_fv:
                      type: string
                      description: |
                        This parameter sets the field of view (fv) for the
                        perspective flip. The string should be formatted as
                        time:(fv_value). Multiple time points can be specified
                        using a | separator.
                      default: 0:(53)
                    noise_schedule:
                      type: string
                      description: |
                        Defines the noise schedule for the animation. The string
                        should be formatted as time:(noise_level). Multiple time
                        points can be specified using a | separator.
                      default: '0: (0.02)'
                    strength_schedule:
                      type: string
                      description: |
                        Sets the strength schedule for the animation. The string
                        should be formatted as time:(strength_level). Multiple
                        time points can be specified using a | separator.
                      default: '0: (0.65)'
                    contrast_schedule:
                      type: string
                      description: |
                        Defines the contrast schedule for the animation. The
                        string should be formatted as time:(contrast_level).
                        Multiple time points can be specified using a |
                        separator.
                      default: '0: (1.0)'
                    hybrid_video_comp_alpha_schedule:
                      type: string
                      description: |
                        Specifies the alpha schedule for hybrid video
                        composition. The string should be formatted as
                        time:(alpha_value). Multiple time points can be
                        specified using a | separator.
                      default: 0:(1)
                    hybrid_video_comp_mask_blend_alpha_schedule:
                      type: string
                      description: |
                        Sets the mask blend alpha schedule for hybrid video
                        composition. The string should be formatted as
                        time:(alpha_value). Multiple time points can be
                        specified using a | separator.
                      default: 0:(0.5)
                    hybrid_video_comp_mask_contrast_schedule:
                      type: string
                      description: |
                        This parameter sets the mask contrast schedule for
                        hybrid video composition. The string should be formatted
                        as time:(contrast_level). Multiple time points can be
                        specified using a | separator.
                      default: 0:(1)
                    hybrid_video_comp_mask_auto_contrast_cutoff_high_schedule:
                      type: string
                      description: |
                        Specifies the high cutoff for the auto contrast mask in
                        the hybrid video composition. The string should be
                        formatted as time:(cutoff_value). Multiple time points
                        can be specified using a | separator.
                      default: 0:(100)
                    hybrid_video_comp_mask_auto_contrast_cutoff_low_schedule:
                      type: string
                      description: |
                        Specifies the low cutoff for the auto contrast mask in
                        the hybrid video composition. The string should be
                        formatted as time:(cutoff_value). Multiple time points
                        can be specified using a | separator.
                      default: 0:(0)
                    enable_schedule_samplers:
                      type: boolean
                      description: |
                        If set to True, it enables the use of schedule samplers
                        in the animation.
                      default: false
                    sampler_schedule:
                      type: string
                      description: |
                        Defines the sampler schedule for the animation. The
                        string should be formatted as time:(sampler_name).
                        Multiple time points can be specified using a |
                        separator.
                      default: |
                        0:('euler'),10:('dpm2'),20:('dpm2_ancestral'),30:('heun'),40:('euler'),50:('euler_ancestral'),60:('dpm_fast'),70:('dpm_adaptive'),80:('dpmpp_2s_a'),90:('dpmpp_2m')
                    kernel_schedule:
                      type: string
                      description: |
                        Sets the kernel schedule for the animation. The string
                        should be formatted as time:(kernel_value). Multiple
                        time points can be specified using a | separator.
                      default: '0: (5)'
                    sigma_schedule:
                      type: string
                      description: |
                        Defines the sigma schedule for the animation. The string
                        should be formatted as time:(sigma_value). Multiple time
                        points can be specified using a | separator.
                      default: '0: (1.0)'
                    amount_schedule:
                      type: string
                      description: |
                        Specifies the amount schedule for the animation. The
                        string should be formatted as time:(amount_value).
                        Multiple time points can be specified using a |
                        separator.
                      default: '0: (0.2)'
                    threshold_schedule:
                      type: string
                      description: |
                        Sets the threshold schedule for the animation. The
                        string should be formatted as time:(threshold_value).
                        Multiple time points can be specified using a |
                        separator.
                      default: '0: (0.0)'
                    color_coherence:
                      type: string
                      description: |
                        Defines the color coherence mode. This parameter can be
                        used to maintain consistent colors across frames. The
                        default setting matches colors with the LAB color space
                        of the first frame.
                      default: Match Frame 0 LAB
                    color_coherence_video_every_N_frames:
                      type: integer
                      description: |
                        Specifies how often color coherence should be calculated
                        for video frames. For instance, a value of 1 means that
                        color coherence is calculated for every frame.
                      default: 1
                      format: int32
                    color_force_grayscale:
                      type: boolean
                      description: |
                        If set to True, the color of the output animation will
                        be forced to grayscale, regardless of the color in the
                        original animation.
                      default: false
                    diffusion_cadence:
                      type: string
                      description: |
                        Defines the diffusion cadence for the animation. The
                        diffusion process can be adjusted to occur after a
                        specific number of frames, as specified by this
                        parameter.
                      default: '1'
                    use_depth_warping:
                      type: boolean
                      description: |
                        Determines whether to use depth warping in the
                        animation. If set to True, the depth warping technique
                        will be applied.
                      default: false
                    midas_weight:
                      type: number
                      description: |
                        Specifies the weight for the MiDAS depth estimation
                        method. Increasing the weight will make the depth
                        estimation more pronounced.
                      default: 0.3
                      format: float
                    near_plane:
                      type: integer
                      description: |
                        Specifies the near plane distance for the 3D projection
                        in the animation. This parameter only has effect when
                        depth warping is enabled.
                      default: 200
                      format: int32
                    far_plane:
                      type: integer
                      description: |
                        Specifies the far plane distance for the 3D projection
                        in the animation. This parameter only has effect when
                        depth warping is enabled.
                      default: 10000
                      format: int32
                    fov:
                      type: integer
                      description: |
                        Defines the field of view for the 3D projection in the
                        animation. This parameter only has effect when depth
                        warping is enabled.
                      default: 40
                      format: int32
                    padding_mode:
                      type: string
                      description: |
                        Determines the padding mode used in the animation. The
                        padding mode can be one of the following options:
                        "border", "reflection", or "zeros".
                      default: border
                    sampling_mode:
                      type: string
                      description: |
                        Specifies the sampling mode for the animation. The
                        sampling mode can be one of the following options:
                        "bicubic", "bilinear", or "nearest".
                      default: bicubic
                    video_init_path:
                      type: string
                      description: |
                        Path to an existing video file to be used as the
                        initialization for the animation generation. If this is
                        not set, a random initialization will be used.
                    extract_nth_frame:
                      type: integer
                      description: |
                        Specifies how many frames to skip when extracting frames
                        from the initialization video. For example, if it's set
                        to 1, every frame will be used. If it's set to 2, every
                        second frame will be used, and so on.
                      default: 1
                      format: int32
                    overwrite_extracted_frames:
                      type: boolean
                      description: |
                        Determines whether to overwrite existing extracted
                        frames when extracting frames from the initialization
                        video.
                      default: false
                    use_mask_video:
                      type: boolean
                      description: |
                        Specifies whether to use a mask video. If set to True,
                        the video specified in input.video_mask_path will be
                        used as a mask.
                      default: false
                    video_mask_path:
                      type: string
                      description: |
                        Path to a video file to be used as a mask, if
                        input.use_mask_video is set to True. The mask video
                        should be a grayscale video where white areas are the
                        regions of interest and black areas are masked out.
                    hybrid_video_generate_inputframes:
                      type: boolean
                      description: |
                        Determines whether to generate input frames for a hybrid
                        video. If True, input frames are generated for the
                        video.
                      default: false
                    hybrid_video_use_first_frame_as_init_image:
                      type: boolean
                      description: |
                        Specifies whether to use the first frame of the hybrid
                        video as the initialization image. If True, the first
                        frame of the video is used for this purpose.
                      default: false
                    hybrid_video_motion:
                      type: string
                      description: |
                        Description: Defines the type of motion to apply in the
                        generation of the hybrid video. Options include "None",
                        "Optical Flow", "Perspective", and "Affine".
                    hybrid_video_flow_method:
                      type: string
                      description: |
                        Specifies the method to calculate optical flow for
                        motion in the hybrid video. Options are "Farneback",
                        "DenseRLOF", and "SF".
                      default: Farneback
                    hybrid_video_composite:
                      type: boolean
                      description: |
                        If set to True, a composite of the input and output
                        videos will be created.
                      default: false
                    hybrid_video_comp_mask_type:
                      type: string
                      description: |
                        Defines the type of mask to use for compositing in the
                        hybrid video. Options include "None", "Depth", "Video
                        Depth", "Blend", and "Difference".
                    hybrid_video_comp_mask_inverse:
                      type: boolean
                      description: |
                        Determines whether to invert the composite mask in the
                        hybrid video. If True, the mask is inverted.
                      default: false
                    hybrid_video_comp_mask_equalize:
                      type: string
                      description: |
                        Specifies when to equalize the mask in the hybrid video.
                        Choices include "None", "Before", "After", and "Both".
                    hybrid_video_comp_mask_auto_contrast:
                      type: boolean
                      description: |
                        If set to True, applies automatic contrast adjustment to
                        the composite mask in the hybrid video.
                      default: false
                    hybrid_video_comp_save_extra_frames:
                      type: boolean
                      description: |
                        Determines whether to save additional frames during the
                        compositing process in the hybrid video. If True, extra
                        frames are saved.
                      default: false
                    hybrid_video_use_video_as_mse_image:
                      type: boolean
                      description: |
                        If set to True, uses the video as the mean squared error
                        (MSE) image during the generation of a hybrid video.
                      default: false
                    interpolate_key_frames:
                      type: boolean
                      description: |
                        Determines whether to interpolate key frames. If True,
                        key frames will be interpolated.
                      default: false
                    interpolate_x_frames:
                      type: integer
                      description: |
                        Specifies the number of frames to interpolate between
                        key frames. Default value is 4.
                      default: 4
                      format: int32
                    resume_from_timestring:
                      type: boolean
                      description: |
                        If set to True, the process resumes from a saved point
                        identified by a timestamp.
                      default: false
                    resume_timestring:
                      type: string
                      description: |
                        Specifies the timestamp string from which to resume the
                        process, if resume_from_timestring is set to True.
                  required: []
                  type: object
                  description: |
                    Input object containing your training parameters, optional
                    inference parameters, optional S3 bucket, and optional
                    webhook.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: '{"video": "LINK-TO-YOUR-VIDEO"}}'
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /lora-trainer/{runtype}:
    post:
      summary: LoRA Trainer
      description: Fine tune a Low-Rank Adaptation model.
      operationId: lora-trainer
      parameters:
        - name: runtype
          in: path
          description: Create asynchronous or synchronous requests.
          schema:
            type: string
            enum:
              - runsync
              - run
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    zip_url:
                      type: string
                      description: |
                        The URL to a publicly accessible zip of your images to
                        be used for training.
                      default: |
                        https://github.com/runpod-workers/sample-inputs/raw/main/images/froggy.zip
                    instance_name:
                      type: string
                      description: |
                        The unique reference name to reference your instance
                        with.
                      default: wixbs
                    class_name:
                      type: string
                      description: |
                        The category your instance belongs to i.e. dog, cat,
                        person
                      default: frog
                    unet_lr:
                      type: number
                      description: Learning rate for the U-Net.
                      default: 0.0001
                      format: float
                    network_dim:
                      type: integer
                      description: Dimension of the network.
                      default: 256
                      format: int32
                    lr_scheduler_num_cycles:
                      type: integer
                      description: Number of cycles of the learning rate scheduler.
                      default: 1
                      format: int32
                    learning_rate:
                      type: number
                      description: Learning rate
                      default: 0.0001
                      format: float
                    lr_scheduler:
                      type: string
                      description: The learning rate to be used.
                      default: cosine
                    lr_warmup_steps:
                      type: integer
                      description: Number of steps for the learning rate warmup.
                      default: 280
                      format: int32
                    train_batch_size:
                      type: integer
                      description: Batch size for training.
                      default: 1
                      format: int32
                    max_train_steps:
                      type: integer
                      description: Maximum number of training steps.
                      default: 1250
                      format: int32
                    mixed_precision:
                      type: string
                      description: Precision type to be used.
                      default: fp16
                    save_precision:
                      type: string
                      description: The precision type used when saving the model.
                      default: fp16
                    optimizer_type:
                      type: string
                      description: 'Type of optimizer used in training. Options: AdamW8bit'
                    max_data_loader_num_workers:
                      type: integer
                      default: 0
                      format: int32
                    steps:
                      type: integer
                      description: The number of steps to train the model for.
                      default: 125
                      format: int32
                  required:
                    - zip_url
                    - instance_name
                    - class_name
                  type: object
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
      deprecated: false
  /sdxl/{run_type}:
    post:
      summary: Stable Diffusion XL
      description: A text-to-image model from StabilityAI
      operationId: stable-diffusion-xl
      parameters:
        - name: run_type
          in: path
          description: |
            Run type, run returns a job ID and runsync returns the results in
            the same call if completed within 30 seconds.
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      description: Your input prompt.
                      default: building 8 stories
                    negative_prompt:
                      type: string
                      description: Specify things to not see in the output.
                    num_inference_steps:
                      type: integer
                      description: The number of denoising steps. Range 1 - 500
                      default: 25
                      format: int32
                    refiner_inference_steps:
                      type: integer
                      description: The number of steps for refiner model.
                      default: 50
                      format: int32
                    width:
                      type: integer
                      description: Width of output image.
                      default: 1024
                      format: int32
                    height:
                      type: integer
                      description: Height of output image.
                      default: 1024
                      format: int32
                    guidance_scale:
                      type: number
                      description: Scale for classifier-free guidance. Rage 1 - 20
                      default: 7.5
                      format: float
                    strength:
                      type: number
                      description: How much changes to make when using Refiner model.
                      default: 0.3
                      format: float
                    image_url:
                      type: string
                      description: URL for an initial image to refine using refiner model.
                    seed:
                      type: integer
                      description: Number used to reproduce output.
                      default: null
                      format: int32
                    num_images:
                      type: integer
                      description: Number of images to generate, max 2.
                      default: 1
                      format: int32
                  required:
                    - prompt
                  type: object
                  description: Input object contains prompt, and more.
                webhook:
                  type: string
                  description: |
                    To be notified of completed jobs, a URL can be passed within
                    the top level of the request.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |-
                    {
                    "id": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
                    "status": "IN_QUEUE"
                    }
              schema:
                type: object
                properties:
                  id:
                    type: string
                    example: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
                  status:
                    type: string
                    example: IN_QUEUE
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '401':
          description: '401'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
        '429':
          description: '429'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
      deprecated: false
  /llama2-13b-chat/{run_type}:
    post:
      summary: Llama2 13B Chat
      description: ''
      operationId: llama2-13b-chat
      parameters:
        - name: run_type
          in: path
          description: |
            Decides whether to run this asynchronously or synchronously. If you
            use "run", then it will be run async and you must use the "Receive
            Output/Status" endpoint with the run id to get your result.
          schema:
            type: string
            enum:
              - runsync
              - run
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      default: Who is the president of the United States?
                    sampling_params:
                      properties:
                        max_tokens:
                          type: integer
                          description: |
                            Maximum number of tokens to generate per output
                            sequence.
                          default: 16
                          format: int32
                        'n':
                          type: integer
                          description: |
                            Number of output sequences to return for the given
                            prompt.
                          default: 1
                          format: int32
                        best_of:
                          type: integer
                          description: |
                            Number of output sequences that are generated from
                            the prompt. From these `best_of` sequences, the top
                            `n` sequences are returned. `best_of` must be
                            greater than or equal to `n`. This is treated as the
                            beam width when `use_beam_search` is True. By
                            default, `best_of` is set to `n`.
                          default: null
                          format: int32
                        presence_penalty:
                          type: number
                          description: |
                            Float that penalizes new tokens based on whether
                            they appear in the generated text so far. Values > 0
                            encourage the model to use new tokens, while values
                            < 0 encourage the model to repeat tokens.
                          default: 0
                          format: float
                        frequency_penalty:
                          type: number
                          description: |
                            Float that penalizes new tokens based on their
                            frequency in the generated text so far. Values > 0
                            encourage the model to use new tokens, while values
                            < 0 encourage the model to repeat tokens.
                          default: 0
                          format: float
                        temperature:
                          type: number
                          description: |
                            Float that controls the randomness of the sampling.
                            Lower values make the model more deterministic,
                            while higher values make the model more random. Zero
                            means greedy sampling.
                          default: 0.7
                          format: float
                        top_p:
                          type: number
                          description: |
                            Float that controls the cumulative probability of
                            the top tokens to consider. Must be in (0, 1]. Set
                            to 1 to consider all tokens.
                          default: 1
                          format: float
                        top_k:
                          type: integer
                          description: |
                            Integer that controls the number of top tokens to
                            consider. Set to -1 to consider all tokens.
                          default: -1
                          format: int32
                        use_beam_search:
                          type: boolean
                          description: Whether to use beam search instead of sampling.
                          default: false
                        stop:
                          type: array
                          description: |
                            List of strings that stop the generation when they
                            are generated. The returned output will not contain
                            the stop strings.
                          default:
                            - None
                          items:
                            type: string
                        ignore_eos:
                          type: boolean
                          description: |
                            Whether to ignore the EOS token and continue
                            generating tokens after the EOS token is generated.
                          default: false
                        logprobs:
                          type: integer
                          description: |
                            Number of log probabilities to return per output
                            token.
                          default: null
                          format: int32
                      required: []
                      type: object
                  required:
                    - prompt
                  type: object
                  description: Inputs to be generated.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                runsync:
                  value: |
                    {

                    "delayTime": 133,

                    "executionTime": 778,

                    "id": "sync-ef63d5da-2904-43be-b961-99883a925c9a",

                    "output": "SYSTEM: You are a helpful assistant.\nUSER: Who
                    is the president of the United States?\nASSISTANT: The
                    current president of the United States is Joe Biden.",

                    "status": "COMPLETED"

                    }
                run:
                  value: |-
                    {
                    "id": "9c6ed893-fda5-4ea6-9e0a-82af9a82403c",
                    "status": "IN_QUEUE"
                    }
              schema:
                oneOf:
                  - title: runsync
                    type: object
                    properties:
                      delayTime:
                        type: integer
                        example: 133
                        default: 0
                      executionTime:
                        type: integer
                        example: 778
                        default: 0
                      id:
                        type: string
                        example: sync-ef63d5da-2904-43be-b961-99883a925c9a
                      output:
                        type: string
                        example: |
                          SYSTEM: You are a helpful assistant.

                          USER: Who is the president of the United States?

                          ASSISTANT: The current president of the United States
                          is Joe Biden.
                      status:
                        type: string
                        example: COMPLETED
                  - title: run
                    type: object
                    properties:
                      id:
                        type: string
                        example: 9c6ed893-fda5-4ea6-9e0a-82af9a82403c
                      status:
                        type: string
                        example: IN_QUEUE
      deprecated: false
      x-readme:
        code-samples:
          - language: curl
            code: |
              curl -v --request POST \

              --url https://api.runpod.ai/v2/llama2-13b-chat/runsync \

              --header 'accept: application/json' \

              --header 'authorization: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'
              \

              --header 'content-type: application/json' \

              --data '

              {

              "input": {

              "prompt": "Who is the president of the United States?",

              "sampling_params": {

              "max_tokens": 100,

              "n": 1,

              "presence_penalty": 0.2,

              "frequency_penalty": 0.7,

              "temperature": 0.3,

              }

              }

              }

              '
        samples-languages:
          - curl
          - python
          - javascript
          - php
          - java
  /llama2-7b-chat/{run_type}:
    post:
      summary: Llama2 7B Chat
      description: ''
      operationId: llama2-7b-chat
      parameters:
        - name: run_type
          in: path
          description: |
            Decides whether to run this asynchronously or synchronously. If you
            use "run", then it will be run async and you must use the "Receive
            Output/Status" endpoint with the run id to get your result.
          schema:
            type: string
            enum:
              - runsync
              - run
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    prompt:
                      type: string
                      default: Who is the president of the United States?
                    sampling_params:
                      properties:
                        max_tokens:
                          type: integer
                          description: |
                            Maximum number of tokens to generate per output
                            sequence.
                          default: 16
                          format: int32
                        'n':
                          type: integer
                          description: |
                            Number of output sequences to return for the given
                            prompt.
                          default: 1
                          format: int32
                        best_of:
                          type: integer
                          description: |
                            Number of output sequences that are generated from
                            the prompt. From these `best_of` sequences, the top
                            `n` sequences are returned. `best_of` must be
                            greater than or equal to `n`. This is treated as the
                            beam width when `use_beam_search` is True. By
                            default, `best_of` is set to `n`.
                          default: null
                          format: int32
                        presence_penalty:
                          type: number
                          description: |
                            Float that penalizes new tokens based on whether
                            they appear in the generated text so far. Values > 0
                            encourage the model to use new tokens, while values
                            < 0 encourage the model to repeat tokens.
                          default: 0
                          format: float
                        frequency_penalty:
                          type: number
                          description: |
                            Float that penalizes new tokens based on their
                            frequency in the generated text so far. Values > 0
                            encourage the model to use new tokens, while values
                            < 0 encourage the model to repeat tokens.
                          default: 0
                          format: float
                        temperature:
                          type: number
                          description: |
                            Float that controls the randomness of the sampling.
                            Lower values make the model more deterministic,
                            while higher values make the model more random. Zero
                            means greedy sampling.
                          default: 0.7
                          format: float
                        top_p:
                          type: number
                          description: |
                            Float that controls the cumulative probability of
                            the top tokens to consider. Must be in (0, 1]. Set
                            to 1 to consider all tokens.
                          default: 1
                          format: float
                        top_k:
                          type: integer
                          description: |
                            Integer that controls the number of top tokens to
                            consider. Set to -1 to consider all tokens.
                          default: -1
                          format: int32
                        use_beam_search:
                          type: boolean
                          description: Whether to use beam search instead of sampling.
                          default: false
                        stop:
                          type: array
                          description: |
                            List of strings that stop the generation when they
                            are generated. The returned output will not contain
                            the stop strings.
                          default:
                            - None
                          items:
                            type: string
                        ignore_eos:
                          type: boolean
                          description: |
                            Whether to ignore the EOS token and continue
                            generating tokens after the EOS token is generated.
                          default: false
                        logprobs:
                          type: integer
                          description: |
                            Number of log probabilities to return per output
                            token.
                          default: null
                          format: int32
                      required: []
                      type: object
                  required:
                    - prompt
                  type: object
                  description: Inputs to be generated.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                runsync:
                  value: |
                    {

                    "delayTime": 133,

                    "executionTime": 778,

                    "id": "sync-ef63d5da-2904-43be-b961-99883a925c9a",

                    "output": "SYSTEM: You are a helpful assistant.\nUSER: Who
                    is the president of the United States?\nASSISTANT: The
                    current president of the United States is Joe Biden.",

                    "status": "COMPLETED"

                    }
                run:
                  value: |-
                    {
                    "id": "9c6ed893-fda5-4ea6-9e0a-82af9a82403c",
                    "status": "IN_QUEUE"
                    }
              schema:
                oneOf:
                  - title: runsync
                    type: object
                    properties:
                      delayTime:
                        type: integer
                        example: 133
                        default: 0
                      executionTime:
                        type: integer
                        example: 778
                        default: 0
                      id:
                        type: string
                        example: sync-ef63d5da-2904-43be-b961-99883a925c9a
                      output:
                        type: string
                        example: |
                          SYSTEM: You are a helpful assistant.

                          USER: Who is the president of the United States?

                          ASSISTANT: The current president of the United States
                          is Joe Biden.
                      status:
                        type: string
                        example: COMPLETED
                  - title: run
                    type: object
                    properties:
                      id:
                        type: string
                        example: 9c6ed893-fda5-4ea6-9e0a-82af9a82403c
                      status:
                        type: string
                        example: IN_QUEUE
      deprecated: false
      x-readme:
        code-samples:
          - language: curl
            code: |
              curl -v --request POST \

              --url https://api.runpod.ai/v2/llama2-7b-chat/runsync \

              --header 'accept: application/json' \

              --header 'authorization: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'
              \

              --header 'content-type: application/json' \

              --data '

              {

              "input": {

              "prompt": "Who is the president of the United States?",

              "sampling_params": {

              "max_tokens": 100,

              "n": 1,

              "presence_penalty": 0.2,

              "frequency_penalty": 0.7,

              "temperature": 0.3,

              }

              }

              }

              '
        samples-languages:
          - curl
  /faster-whisper/{run_type}:
    post:
      summary: Faster-Whisper
      description: Whisper is an automatic speech recognition (ASR) system.
      operationId: faster-whisper
      parameters:
        - name: run_type
          in: path
          schema:
            type: string
            enum:
              - run
              - runsync
            default: runsync
          required: true
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  properties:
                    audio:
                      type: string
                      description: The URL of the input audio file.
                      default: |
                        https://github.com/runpod-workers/sample-inputs/raw/main/audio/gettysburg.wav
                    model:
                      type: string
                      description: |
                        Choose a Whisper model. Options: tiny, base, small,
                        medium, large-v1, large-v2
                      default: base
                    transcription:
                      type: string
                      description: |
                        Choose the format for the transcription. Options:
                        plain_text, srt, vtt
                      default: plain_text
                    translate:
                      type: boolean
                      description: Translate the text to English when set to True.
                      default: false
                    language:
                      type: string
                      description: |
                        Language spoken in the audio, specify None to perform
                        language detection.
                      default: en
                    temperature:
                      type: number
                      description: Temperature to use for sampling.
                      default: 0
                      format: float
                    best_of:
                      type: integer
                      description: |
                        The number of candidates when sampling with non-zero
                        temperature.
                      default: 5
                      format: int32
                    beam_size:
                      type: integer
                      description: |
                        Number of beams in beam search, only applicable when
                        temperature is zero.
                      default: 5
                      format: int32
                    patience:
                      type: number
                      description: Optional patience value to use in beam decoding.
                      default: 1
                      format: float
                    suppress_tokens:
                      type: string
                      description: |
                        Comma-separated list of token ids to suppress during
                        sampling; '-1' will suppress most special characters
                        except common punctuations.
                      default: '-1'
                    length_penalty:
                      type: number
                      description: |
                        Optional token length penalty coefficient (alpha). Uses
                        simple length normalization by default.
                      format: float
                    initial_prompt:
                      type: string
                      description: |
                        Optional text to provide as a prompt for the first
                        window.
                    condition_on_previous_text:
                      type: boolean
                      description: |
                        If True, provide the previous output of the model as a
                        prompt for the next window; disabling may make the text
                        inconsistent across windows, but the model becomes less
                        prone to getting stuck in a failure loop.
                      default: false
                    temperature_increment_on_fallback:
                      type: number
                      description: |
                        Temperature to increase when falling back when the
                        decoding fails to meet either of the thresholds below.
                      default: 0.2
                      format: float
                    compression_ratio_threshold:
                      type: number
                      description: |
                        If the gzip compression ration is higher than this
                        value, treat the decoding as failed.
                      default: 2.4
                      format: float
                    logprob_threshold:
                      type: number
                      description: |
                        If the average log probability is lower than this value,
                        treat the decoding as failed.
                      default: -1
                      format: float
                    no_speech_threshold:
                      type: number
                      description: |
                        If the probability of the <|nospeech|> token is higher
                        than this value AND the decoding has failed due to
                        'logprob_threshold', consider the segment as silence.
                      default: 0.6
                      format: float
                  required:
                    - audio
                  type: object
                  description: Input that contains prompts and more.
      responses:
        '200':
          description: '200'
          content:
            application/json:
              examples:
                Result:
                  value: |
                    {

                    "delayTime": 944,

                    "executionTime": 2406,

                    "id": "sync-8f2aacb9-d354-491f-8df7-40aab8b245ac",

                    "output": {

                    "detected_language": "en",

                    "segments": [

                    {

                    "avg_logprob": -0.18211127616263725,

                    "compression_ratio": 1.3858267716535433,

                    "end": 10,

                    "id": 1,

                    "no_speech_prob": 0.019287109375,

                    "seek": 1000,

                    "start": 0,

                    "temperature": 0.1,

                    "text": " Four score and seven years ago, our fathers
                    brought forth on this continent a new nation, conceived in
                    liberty, and dedicated to the proposition that all men are
                    created equal.",

                    "tokens": [

                    50364,

                    7451,

                    6175,

                    293,

                    3407,

                    924,

                    2057,

                    11,

                    527,

                    23450,

                    3038,

                    5220,

                    322,

                    341,

                    18932,

                    257,

                    777,

                    4790,

                    11,

                    34898,

                    294,

                    22849,

                    11,

                    293,

                    8374,

                    281,

                    264,

                    24830,

                    300,

                    439,

                    1706,

                    366,

                    2942,

                    2681,

                    13,

                    50864

                    ]

                    }

                    ],

                    "transcription": "00:00.000 --> 00:10.000\nFour score and
                    seven years ago, our fathers brought forth on this continent
                    a new nation, conceived in liberty, and dedicated to the
                    proposition that all men are created equal.\n\n",

                    "translation": null

                    },

                    "status": "COMPLETED"

                    }
              schema:
                type: object
                properties:
                  delayTime:
                    type: integer
                    example: 944
                    default: 0
                  executionTime:
                    type: integer
                    example: 2406
                    default: 0
                  id:
                    type: string
                    example: sync-8f2aacb9-d354-491f-8df7-40aab8b245ac
                  output:
                    type: object
                    properties:
                      detected_language:
                        type: string
                        example: en
                      segments:
                        type: array
                        items:
                          type: object
                          properties:
                            avg_logprob:
                              type: number
                              example: -0.18211127616263725
                              default: 0
                            compression_ratio:
                              type: number
                              example: 1.3858267716535433
                              default: 0
                            end:
                              type: integer
                              example: 10
                              default: 0
                            id:
                              type: integer
                              example: 1
                              default: 0
                            no_speech_prob:
                              type: number
                              example: 0.019287109375
                              default: 0
                            seek:
                              type: integer
                              example: 1000
                              default: 0
                            start:
                              type: integer
                              example: 0
                              default: 0
                            temperature:
                              type: number
                              example: 0.1
                              default: 0
                            text:
                              type: string
                              example: |
                                Four score and seven years ago, our fathers
                                brought forth on this continent a new nation,
                                conceived in liberty, and dedicated to the
                                proposition that all men are created equal.
                            tokens:
                              type: array
                              items:
                                type: integer
                                example: 50364
                                default: 0
                      transcription:
                        type: string
                        example: >
                          00:00.000 --> 00:10.000

                          Four score and seven years ago, our fathers brought
                          forth on this continent a new nation, conceived in
                          liberty, and dedicated to the proposition that all men
                          are created equal.
                      translation: {}
                  status:
                    type: string
                    example: COMPLETED
        '400':
          description: '400'
          content:
            application/json:
              examples:
                Result:
                  value: '{}'
              schema:
                type: object
                properties: {}
        '401':
          description: '401'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
        '429':
          description: '429'
          content:
            text/plain:
              examples:
                Result:
                  value: ''
      deprecated: false
